{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1 subject. Feature extraction. Classification for each frequency band."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "\r\n",
    "#def select_file(file):\r\n",
    "    #Lectura mediante pandas\r\n",
    "f = \"data_preprocessed_python\\\\s32.dat\"\r\n",
    "subject_id = 32\r\n",
    "\r\n",
    "dictRaw = pd.read_pickle(f)\r\n",
    "\r\n",
    "labels = dictRaw.get('labels')\r\n",
    "\r\n",
    "dfLabels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\r\n",
    "\r\n",
    "data = dictRaw.get('data')\r\n",
    "\r\n",
    "df_videos = {}\r\n",
    "    #Recorrido de cada una de las columnas de la tabla 3d, y guardado en una una lista de dataframes para cada uno de los videos.\r\n",
    "for i in range(40):\r\n",
    "    df_videos[i] = pd.DataFrame(data[i])\r\n",
    "    df_videos[i] = df_videos[i].transpose()\r\n",
    "    df_videos[i].columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature']\r\n",
    "    df_videos[i].drop(['hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature'],axis = 'columns', inplace=True)\r\n",
    "#df_videos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "    # Frecuencia de muestreo\r\n",
    "    fs = 128\r\n",
    "    # Window\r\n",
    "    window = \"hann\"\r\n",
    "    # Length of each segment\r\n",
    "    # nperseg = 256 por defecto\r\n",
    "    # noverlap\r\n",
    "    # Por defecto a None, if None : noverlap = nperseg / 2\r\n",
    "    # [...]\r\n",
    "\r\n",
    "    # Definicion de bandas\r\n",
    "    eeg_bands = {'Delta': (1, 4),\r\n",
    "                'Theta': (4, 8),\r\n",
    "                'Alpha': (8, 14),\r\n",
    "                'Beta': (14, 30),\r\n",
    "                'Gamma': (30, 50)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# FOURIER\r\n",
    "import scipy\r\n",
    "from scipy import signal\r\n",
    "\r\n",
    "def do_stft(video, channel):\r\n",
    "    # Array \r\n",
    "    x = df_videos[video][channel]\r\n",
    "\r\n",
    "    # Array of the sample frequency, Array of the segment times, STFT of x\r\n",
    "    f, t , Zxx = scipy.signal.stft(x, fs, window)\r\n",
    "\r\n",
    "    return Zxx\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#SEPARACION EN LAS DISTINTAS BANDAS DE FRECUENCIA\r\n",
    "\r\n",
    "def make_bands(Zxx):\r\n",
    "    #Obtener valores reales de STFT, solo positivos.\r\n",
    "    values = np.absolute(Zxx)\r\n",
    "\r\n",
    "    # Get frequencies for amplitudes in Hz\r\n",
    "    fft_freq = np.fft.rfftfreq(len(data), 1.0/fs)\r\n",
    "    #print(fft_freq)\r\n",
    "\r\n",
    "    # Obtención de cada una de las bandas de frecuencia\r\n",
    "    eeg_band_fft = dict()\r\n",
    "    for band in eeg_bands:  \r\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq <= eeg_bands[band][1]))[0]\r\n",
    "        eeg_band_fft[band] = values[freq_ix]\r\n",
    "\r\n",
    "    #print(eeg_band_fft)\r\n",
    "    '''\r\n",
    "    eeg_band_fft_means = dict()\r\n",
    "    for band in eeg_bands:  \r\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq <= eeg_bands[band][1]))[0]\r\n",
    "        eeg_band_fft_means[band] = np.mean(values[freq_ix])\r\n",
    "\r\n",
    "    #print(eeg_band_fft_means)\r\n",
    "\r\n",
    "    #Graficación de las medias de los datos\r\n",
    "    df = pd.DataFrame(columns=['band', 'val'])\r\n",
    "    df['band'] = eeg_bands.keys()\r\n",
    "    df['val'] = [eeg_band_fft_means[band] for band in eeg_bands]\r\n",
    "    ax = df.plot.bar(x='band', y='val', legend=False)\r\n",
    "    ax.set_xlabel(\"EEG band\")\r\n",
    "    ax.set_ylabel(\"Mean band Amplitude\")\r\n",
    "    '''\r\n",
    "    #print(df)\r\n",
    "\r\n",
    "    #print(\"\\n\\n\")\r\n",
    "\r\n",
    "    '''\r\n",
    "    print(\"Shape de Zxx: \", Zxx.shape)\r\n",
    "    print(\"Shape de Delta: \", eeg_band_fft['Delta'].shape)\r\n",
    "    print(\"Shape de Theta: \", eeg_band_fft['Theta'].shape)\r\n",
    "    print(\"Shape de Alpha: \", eeg_band_fft['Alpha'].shape)\r\n",
    "    print(\"Shape de Beta: \", eeg_band_fft['Beta'].shape)\r\n",
    "    print(\"Shape de Gamma: \", eeg_band_fft['Gamma'].shape)\r\n",
    "    '''\r\n",
    "    return eeg_band_fft\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Ahora hay que hacer las medias sobre cada banda de frecuencia. La media entre cada una de las posiciones de los bloques. Hacer la media entre todas las posiciones 0, 1, 2... 63 de cada uno de los bloques\r\n",
    "def channel_freq(eeg_band_fft):\r\n",
    "        \r\n",
    "        freq = np.zeros((5, 64))        # 5 bandas, 64 posiciones de los datos\r\n",
    "\r\n",
    "        # Se va a recorrer {Delta, Theta, Alpha, Beta, Gamma}\r\n",
    "        for band in eeg_bands:\r\n",
    "\r\n",
    "                # Para cada una de las 64 posiciones del array\r\n",
    "                for j in range (0, 64):\r\n",
    "                        \r\n",
    "                        val = []\r\n",
    "                        # Se va a recorrer cada uno de los arrays que hay en cada una de las bandas\r\n",
    "                        for i in range (0, len(eeg_band_fft[band])):\r\n",
    "                                val.append(eeg_band_fft[band][i][j])\r\n",
    "                                # Ejemplo : eeg_band_fft['Delta'][0][0*0 + 0]\r\n",
    "                        if (band == \"Delta\"):\r\n",
    "                                freq[0][j] = np.mean(val)\r\n",
    "                        elif (band == \"Theta\"):\r\n",
    "                                freq[1][j] = np.mean(val)\r\n",
    "                        elif (band == \"Alpha\"):\r\n",
    "                                freq[2][j] = np.mean(val)\r\n",
    "                        elif (band == \"Beta\"):\r\n",
    "                                freq[3][j] = np.mean(val)\r\n",
    "                        elif (band == \"Gamma\"):\r\n",
    "                                freq[4][j] = np.mean(val)\r\n",
    "        return(freq)     # En freq tenemos las frecuencias medias de cada una de las bandas\r\n",
    "\r\n",
    "# Recordamos : Estamos tratando los datos relativos al video 0, un canal concreto de un sujeto concreto"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#df_file_videos = select_file('d\\\\s01.dat')\r\n",
    "# Obtener la división por bandas de frecuencia de cada uno de los canales del video 0\r\n",
    "for video in range(0, 40):\r\n",
    "    delta_bands = []\r\n",
    "    theta_bands = []\r\n",
    "    beta_bands = []\r\n",
    "    alpha_bands = []\r\n",
    "    gamma_bands = []\r\n",
    "\r\n",
    "    for channel in ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']:\r\n",
    "        Zxx = do_stft(video, channel)\r\n",
    "        eeg_band_fft = make_bands(Zxx)\r\n",
    "        freq = channel_freq(eeg_band_fft)\r\n",
    "\r\n",
    "        delta_bands.append(freq[0])\r\n",
    "        theta_bands.append(freq[1])\r\n",
    "        alpha_bands.append(freq[2])\r\n",
    "        beta_bands.append(freq[3])\r\n",
    "        gamma_bands.append(freq[4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Banda delta\r\n",
    "df = pd.DataFrame(delta_bands)\r\n",
    "delta_df = df.transpose()\r\n",
    "delta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "delta_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in delta_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_delta = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_delta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.025366  0.078844  0.039507  0.094259  0.044156  0.037892  0.034969   \n",
       "1     0.025366  0.078844  0.039507  0.094259  0.044156  0.037892  0.034969   \n",
       "2     0.025366  0.078844  0.039507  0.094259  0.044156  0.037892  0.034969   \n",
       "3     0.025366  0.078844  0.039507  0.094259  0.044156  0.037892  0.034969   \n",
       "4     0.025366  0.078844  0.039507  0.094259  0.044156  0.037892  0.034969   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.022481  0.172611  0.057046  0.109849  0.242265  0.070911  0.196101   \n",
       "2556  0.022481  0.172611  0.057046  0.109849  0.242265  0.070911  0.196101   \n",
       "2557  0.022481  0.172611  0.057046  0.109849  0.242265  0.070911  0.196101   \n",
       "2558  0.022481  0.172611  0.057046  0.109849  0.242265  0.070911  0.196101   \n",
       "2559  0.022481  0.172611  0.057046  0.109849  0.242265  0.070911  0.196101   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     0.148271  0.164957  0.033372  ...  0.372899  0.035648  0.065213   \n",
       "1     0.148271  0.164957  0.033372  ...  0.372899  0.035648  0.065213   \n",
       "2     0.148271  0.164957  0.033372  ...  0.372899  0.035648  0.065213   \n",
       "3     0.148271  0.164957  0.033372  ...  0.372899  0.035648  0.065213   \n",
       "4     0.148271  0.164957  0.033372  ...  0.372899  0.035648  0.065213   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  0.334543  0.355690  0.188437  ...  1.544856  0.022754  0.107385   \n",
       "2556  0.334543  0.355690  0.188437  ...  1.544856  0.022754  0.107385   \n",
       "2557  0.334543  0.355690  0.188437  ...  1.544856  0.022754  0.107385   \n",
       "2558  0.334543  0.355690  0.188437  ...  1.544856  0.022754  0.107385   \n",
       "2559  0.334543  0.355690  0.188437  ...  1.544856  0.022754  0.107385   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.052704  0.213639  0.099711  0.048500  0.074329  0.140679  0.029246  \n",
       "1     0.052704  0.213639  0.099711  0.048500  0.074329  0.140679  0.029246  \n",
       "2     0.052704  0.213639  0.099711  0.048500  0.074329  0.140679  0.029246  \n",
       "3     0.052704  0.213639  0.099711  0.048500  0.074329  0.140679  0.029246  \n",
       "4     0.052704  0.213639  0.099711  0.048500  0.074329  0.140679  0.029246  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.062702  0.663288  0.398949  0.165376  0.216283  0.609451  0.048894  \n",
       "2556  0.062702  0.663288  0.398949  0.165376  0.216283  0.609451  0.048894  \n",
       "2557  0.062702  0.663288  0.398949  0.165376  0.216283  0.609451  0.048894  \n",
       "2558  0.062702  0.663288  0.398949  0.165376  0.216283  0.609451  0.048894  \n",
       "2559  0.062702  0.663288  0.398949  0.165376  0.216283  0.609451  0.048894  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.078844</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.035648</td>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>0.099711</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.029246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.078844</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.035648</td>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>0.099711</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.029246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.078844</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.035648</td>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>0.099711</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.029246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.078844</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.035648</td>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>0.099711</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.029246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.078844</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.035648</td>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>0.099711</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.029246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.172611</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.109849</td>\n",
       "      <td>0.242265</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.196101</td>\n",
       "      <td>0.334543</td>\n",
       "      <td>0.355690</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.544856</td>\n",
       "      <td>0.022754</td>\n",
       "      <td>0.107385</td>\n",
       "      <td>0.062702</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.398949</td>\n",
       "      <td>0.165376</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>0.609451</td>\n",
       "      <td>0.048894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.172611</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.109849</td>\n",
       "      <td>0.242265</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.196101</td>\n",
       "      <td>0.334543</td>\n",
       "      <td>0.355690</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.544856</td>\n",
       "      <td>0.022754</td>\n",
       "      <td>0.107385</td>\n",
       "      <td>0.062702</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.398949</td>\n",
       "      <td>0.165376</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>0.609451</td>\n",
       "      <td>0.048894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.172611</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.109849</td>\n",
       "      <td>0.242265</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.196101</td>\n",
       "      <td>0.334543</td>\n",
       "      <td>0.355690</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.544856</td>\n",
       "      <td>0.022754</td>\n",
       "      <td>0.107385</td>\n",
       "      <td>0.062702</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.398949</td>\n",
       "      <td>0.165376</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>0.609451</td>\n",
       "      <td>0.048894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.172611</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.109849</td>\n",
       "      <td>0.242265</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.196101</td>\n",
       "      <td>0.334543</td>\n",
       "      <td>0.355690</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.544856</td>\n",
       "      <td>0.022754</td>\n",
       "      <td>0.107385</td>\n",
       "      <td>0.062702</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.398949</td>\n",
       "      <td>0.165376</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>0.609451</td>\n",
       "      <td>0.048894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.172611</td>\n",
       "      <td>0.057046</td>\n",
       "      <td>0.109849</td>\n",
       "      <td>0.242265</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.196101</td>\n",
       "      <td>0.334543</td>\n",
       "      <td>0.355690</td>\n",
       "      <td>0.188437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.544856</td>\n",
       "      <td>0.022754</td>\n",
       "      <td>0.107385</td>\n",
       "      <td>0.062702</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.398949</td>\n",
       "      <td>0.165376</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>0.609451</td>\n",
       "      <td>0.048894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Banda theta\r\n",
    "df = pd.DataFrame(theta_bands)\r\n",
    "theta_df = df.transpose()\r\n",
    "theta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "theta_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in theta_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_theta = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_theta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.018908  0.119647  0.045046  0.120408  0.052348  0.033803  0.062029   \n",
       "1     0.018908  0.119647  0.045046  0.120408  0.052348  0.033803  0.062029   \n",
       "2     0.018908  0.119647  0.045046  0.120408  0.052348  0.033803  0.062029   \n",
       "3     0.018908  0.119647  0.045046  0.120408  0.052348  0.033803  0.062029   \n",
       "4     0.018908  0.119647  0.045046  0.120408  0.052348  0.033803  0.062029   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.024220  0.166680  0.067325  0.147044  0.244436  0.073475  0.191783   \n",
       "2556  0.024220  0.166680  0.067325  0.147044  0.244436  0.073475  0.191783   \n",
       "2557  0.024220  0.166680  0.067325  0.147044  0.244436  0.073475  0.191783   \n",
       "2558  0.024220  0.166680  0.067325  0.147044  0.244436  0.073475  0.191783   \n",
       "2559  0.024220  0.166680  0.067325  0.147044  0.244436  0.073475  0.191783   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     0.194587  0.230034  0.050673  ...  0.575209  0.041922  0.079025   \n",
       "1     0.194587  0.230034  0.050673  ...  0.575209  0.041922  0.079025   \n",
       "2     0.194587  0.230034  0.050673  ...  0.575209  0.041922  0.079025   \n",
       "3     0.194587  0.230034  0.050673  ...  0.575209  0.041922  0.079025   \n",
       "4     0.194587  0.230034  0.050673  ...  0.575209  0.041922  0.079025   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  0.327033  0.346295  0.224839  ...  1.607303  0.034971  0.120223   \n",
       "2556  0.327033  0.346295  0.224839  ...  1.607303  0.034971  0.120223   \n",
       "2557  0.327033  0.346295  0.224839  ...  1.607303  0.034971  0.120223   \n",
       "2558  0.327033  0.346295  0.224839  ...  1.607303  0.034971  0.120223   \n",
       "2559  0.327033  0.346295  0.224839  ...  1.607303  0.034971  0.120223   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.087149  0.303126  0.145937  0.071534  0.109496  0.221562  0.047842  \n",
       "1     0.087149  0.303126  0.145937  0.071534  0.109496  0.221562  0.047842  \n",
       "2     0.087149  0.303126  0.145937  0.071534  0.109496  0.221562  0.047842  \n",
       "3     0.087149  0.303126  0.145937  0.071534  0.109496  0.221562  0.047842  \n",
       "4     0.087149  0.303126  0.145937  0.071534  0.109496  0.221562  0.047842  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.043455  0.680246  0.414566  0.172088  0.201217  0.634894  0.061363  \n",
       "2556  0.043455  0.680246  0.414566  0.172088  0.201217  0.634894  0.061363  \n",
       "2557  0.043455  0.680246  0.414566  0.172088  0.201217  0.634894  0.061363  \n",
       "2558  0.043455  0.680246  0.414566  0.172088  0.201217  0.634894  0.061363  \n",
       "2559  0.043455  0.680246  0.414566  0.172088  0.201217  0.634894  0.061363  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.119647</td>\n",
       "      <td>0.045046</td>\n",
       "      <td>0.120408</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.062029</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575209</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.087149</td>\n",
       "      <td>0.303126</td>\n",
       "      <td>0.145937</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>0.109496</td>\n",
       "      <td>0.221562</td>\n",
       "      <td>0.047842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.119647</td>\n",
       "      <td>0.045046</td>\n",
       "      <td>0.120408</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.062029</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575209</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.087149</td>\n",
       "      <td>0.303126</td>\n",
       "      <td>0.145937</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>0.109496</td>\n",
       "      <td>0.221562</td>\n",
       "      <td>0.047842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.119647</td>\n",
       "      <td>0.045046</td>\n",
       "      <td>0.120408</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.062029</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575209</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.087149</td>\n",
       "      <td>0.303126</td>\n",
       "      <td>0.145937</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>0.109496</td>\n",
       "      <td>0.221562</td>\n",
       "      <td>0.047842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.119647</td>\n",
       "      <td>0.045046</td>\n",
       "      <td>0.120408</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.062029</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575209</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.087149</td>\n",
       "      <td>0.303126</td>\n",
       "      <td>0.145937</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>0.109496</td>\n",
       "      <td>0.221562</td>\n",
       "      <td>0.047842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018908</td>\n",
       "      <td>0.119647</td>\n",
       "      <td>0.045046</td>\n",
       "      <td>0.120408</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>0.062029</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575209</td>\n",
       "      <td>0.041922</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.087149</td>\n",
       "      <td>0.303126</td>\n",
       "      <td>0.145937</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>0.109496</td>\n",
       "      <td>0.221562</td>\n",
       "      <td>0.047842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.166680</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.147044</td>\n",
       "      <td>0.244436</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.191783</td>\n",
       "      <td>0.327033</td>\n",
       "      <td>0.346295</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607303</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.120223</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.680246</td>\n",
       "      <td>0.414566</td>\n",
       "      <td>0.172088</td>\n",
       "      <td>0.201217</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.061363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.166680</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.147044</td>\n",
       "      <td>0.244436</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.191783</td>\n",
       "      <td>0.327033</td>\n",
       "      <td>0.346295</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607303</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.120223</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.680246</td>\n",
       "      <td>0.414566</td>\n",
       "      <td>0.172088</td>\n",
       "      <td>0.201217</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.061363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.166680</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.147044</td>\n",
       "      <td>0.244436</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.191783</td>\n",
       "      <td>0.327033</td>\n",
       "      <td>0.346295</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607303</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.120223</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.680246</td>\n",
       "      <td>0.414566</td>\n",
       "      <td>0.172088</td>\n",
       "      <td>0.201217</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.061363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.166680</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.147044</td>\n",
       "      <td>0.244436</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.191783</td>\n",
       "      <td>0.327033</td>\n",
       "      <td>0.346295</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607303</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.120223</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.680246</td>\n",
       "      <td>0.414566</td>\n",
       "      <td>0.172088</td>\n",
       "      <td>0.201217</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.061363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.166680</td>\n",
       "      <td>0.067325</td>\n",
       "      <td>0.147044</td>\n",
       "      <td>0.244436</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.191783</td>\n",
       "      <td>0.327033</td>\n",
       "      <td>0.346295</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.607303</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>0.120223</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.680246</td>\n",
       "      <td>0.414566</td>\n",
       "      <td>0.172088</td>\n",
       "      <td>0.201217</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.061363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Bnada alpha\r\n",
    "df = pd.DataFrame(alpha_bands)\r\n",
    "alpha_df = df.transpose()\r\n",
    "alpha_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "alpha_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in alpha_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_alpha = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_alpha"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.018843  0.164569  0.063804  0.156485  0.093022  0.038792  0.091270   \n",
       "1     0.018843  0.164569  0.063804  0.156485  0.093022  0.038792  0.091270   \n",
       "2     0.018843  0.164569  0.063804  0.156485  0.093022  0.038792  0.091270   \n",
       "3     0.018843  0.164569  0.063804  0.156485  0.093022  0.038792  0.091270   \n",
       "4     0.018843  0.164569  0.063804  0.156485  0.093022  0.038792  0.091270   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.037833  0.188339  0.094489  0.242650  0.306649  0.087516  0.219157   \n",
       "2556  0.037833  0.188339  0.094489  0.242650  0.306649  0.087516  0.219157   \n",
       "2557  0.037833  0.188339  0.094489  0.242650  0.306649  0.087516  0.219157   \n",
       "2558  0.037833  0.188339  0.094489  0.242650  0.306649  0.087516  0.219157   \n",
       "2559  0.037833  0.188339  0.094489  0.242650  0.306649  0.087516  0.219157   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     0.236123  0.288100  0.073060  ...  0.779159  0.043292  0.105756   \n",
       "1     0.236123  0.288100  0.073060  ...  0.779159  0.043292  0.105756   \n",
       "2     0.236123  0.288100  0.073060  ...  0.779159  0.043292  0.105756   \n",
       "3     0.236123  0.288100  0.073060  ...  0.779159  0.043292  0.105756   \n",
       "4     0.236123  0.288100  0.073060  ...  0.779159  0.043292  0.105756   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  0.374257  0.418595  0.349438  ...  2.126998  0.055798  0.156946   \n",
       "2556  0.374257  0.418595  0.349438  ...  2.126998  0.055798  0.156946   \n",
       "2557  0.374257  0.418595  0.349438  ...  2.126998  0.055798  0.156946   \n",
       "2558  0.374257  0.418595  0.349438  ...  2.126998  0.055798  0.156946   \n",
       "2559  0.374257  0.418595  0.349438  ...  2.126998  0.055798  0.156946   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.133018  0.398716  0.203477  0.103539  0.140532  0.303441  0.065347  \n",
       "1     0.133018  0.398716  0.203477  0.103539  0.140532  0.303441  0.065347  \n",
       "2     0.133018  0.398716  0.203477  0.103539  0.140532  0.303441  0.065347  \n",
       "3     0.133018  0.398716  0.203477  0.103539  0.140532  0.303441  0.065347  \n",
       "4     0.133018  0.398716  0.203477  0.103539  0.140532  0.303441  0.065347  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.060423  0.849186  0.512698  0.201694  0.223133  0.830502  0.104939  \n",
       "2556  0.060423  0.849186  0.512698  0.201694  0.223133  0.830502  0.104939  \n",
       "2557  0.060423  0.849186  0.512698  0.201694  0.223133  0.830502  0.104939  \n",
       "2558  0.060423  0.849186  0.512698  0.201694  0.223133  0.830502  0.104939  \n",
       "2559  0.060423  0.849186  0.512698  0.201694  0.223133  0.830502  0.104939  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.164569</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>0.156485</td>\n",
       "      <td>0.093022</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.236123</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.073060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779159</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.398716</td>\n",
       "      <td>0.203477</td>\n",
       "      <td>0.103539</td>\n",
       "      <td>0.140532</td>\n",
       "      <td>0.303441</td>\n",
       "      <td>0.065347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.164569</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>0.156485</td>\n",
       "      <td>0.093022</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.236123</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.073060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779159</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.398716</td>\n",
       "      <td>0.203477</td>\n",
       "      <td>0.103539</td>\n",
       "      <td>0.140532</td>\n",
       "      <td>0.303441</td>\n",
       "      <td>0.065347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.164569</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>0.156485</td>\n",
       "      <td>0.093022</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.236123</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.073060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779159</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.398716</td>\n",
       "      <td>0.203477</td>\n",
       "      <td>0.103539</td>\n",
       "      <td>0.140532</td>\n",
       "      <td>0.303441</td>\n",
       "      <td>0.065347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.164569</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>0.156485</td>\n",
       "      <td>0.093022</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.236123</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.073060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779159</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.398716</td>\n",
       "      <td>0.203477</td>\n",
       "      <td>0.103539</td>\n",
       "      <td>0.140532</td>\n",
       "      <td>0.303441</td>\n",
       "      <td>0.065347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.164569</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>0.156485</td>\n",
       "      <td>0.093022</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.236123</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.073060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779159</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.398716</td>\n",
       "      <td>0.203477</td>\n",
       "      <td>0.103539</td>\n",
       "      <td>0.140532</td>\n",
       "      <td>0.303441</td>\n",
       "      <td>0.065347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.037833</td>\n",
       "      <td>0.188339</td>\n",
       "      <td>0.094489</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.306649</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>0.219157</td>\n",
       "      <td>0.374257</td>\n",
       "      <td>0.418595</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126998</td>\n",
       "      <td>0.055798</td>\n",
       "      <td>0.156946</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.849186</td>\n",
       "      <td>0.512698</td>\n",
       "      <td>0.201694</td>\n",
       "      <td>0.223133</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.104939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.037833</td>\n",
       "      <td>0.188339</td>\n",
       "      <td>0.094489</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.306649</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>0.219157</td>\n",
       "      <td>0.374257</td>\n",
       "      <td>0.418595</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126998</td>\n",
       "      <td>0.055798</td>\n",
       "      <td>0.156946</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.849186</td>\n",
       "      <td>0.512698</td>\n",
       "      <td>0.201694</td>\n",
       "      <td>0.223133</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.104939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.037833</td>\n",
       "      <td>0.188339</td>\n",
       "      <td>0.094489</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.306649</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>0.219157</td>\n",
       "      <td>0.374257</td>\n",
       "      <td>0.418595</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126998</td>\n",
       "      <td>0.055798</td>\n",
       "      <td>0.156946</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.849186</td>\n",
       "      <td>0.512698</td>\n",
       "      <td>0.201694</td>\n",
       "      <td>0.223133</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.104939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.037833</td>\n",
       "      <td>0.188339</td>\n",
       "      <td>0.094489</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.306649</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>0.219157</td>\n",
       "      <td>0.374257</td>\n",
       "      <td>0.418595</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126998</td>\n",
       "      <td>0.055798</td>\n",
       "      <td>0.156946</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.849186</td>\n",
       "      <td>0.512698</td>\n",
       "      <td>0.201694</td>\n",
       "      <td>0.223133</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.104939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.037833</td>\n",
       "      <td>0.188339</td>\n",
       "      <td>0.094489</td>\n",
       "      <td>0.242650</td>\n",
       "      <td>0.306649</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>0.219157</td>\n",
       "      <td>0.374257</td>\n",
       "      <td>0.418595</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>...</td>\n",
       "      <td>2.126998</td>\n",
       "      <td>0.055798</td>\n",
       "      <td>0.156946</td>\n",
       "      <td>0.060423</td>\n",
       "      <td>0.849186</td>\n",
       "      <td>0.512698</td>\n",
       "      <td>0.201694</td>\n",
       "      <td>0.223133</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.104939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Banda beta\r\n",
    "df = pd.DataFrame(beta_bands)\r\n",
    "beta_df = df.transpose()\r\n",
    "beta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "beta_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in beta_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_beta = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_beta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.070166  1.060305  0.308343  0.835856  0.636678  0.270968  0.687164   \n",
       "1     0.070166  1.060305  0.308343  0.835856  0.636678  0.270968  0.687164   \n",
       "2     0.070166  1.060305  0.308343  0.835856  0.636678  0.270968  0.687164   \n",
       "3     0.070166  1.060305  0.308343  0.835856  0.636678  0.270968  0.687164   \n",
       "4     0.070166  1.060305  0.308343  0.835856  0.636678  0.270968  0.687164   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.244119  0.542509  0.365433  1.300983  0.742717  0.264139  0.398248   \n",
       "2556  0.244119  0.542509  0.365433  1.300983  0.742717  0.264139  0.398248   \n",
       "2557  0.244119  0.542509  0.365433  1.300983  0.742717  0.264139  0.398248   \n",
       "2558  0.244119  0.542509  0.365433  1.300983  0.742717  0.264139  0.398248   \n",
       "2559  0.244119  0.542509  0.365433  1.300983  0.742717  0.264139  0.398248   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     1.028565  1.138698  0.257403  ...  3.746501  0.065353  0.510457   \n",
       "1     1.028565  1.138698  0.257403  ...  3.746501  0.065353  0.510457   \n",
       "2     1.028565  1.138698  0.257403  ...  3.746501  0.065353  0.510457   \n",
       "3     1.028565  1.138698  0.257403  ...  3.746501  0.065353  0.510457   \n",
       "4     1.028565  1.138698  0.257403  ...  3.746501  0.065353  0.510457   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  1.000291  0.857970  1.323068  ...  6.083535  0.337323  0.717518   \n",
       "2556  1.000291  0.857970  1.323068  ...  6.083535  0.337323  0.717518   \n",
       "2557  1.000291  0.857970  1.323068  ...  6.083535  0.337323  0.717518   \n",
       "2558  1.000291  0.857970  1.323068  ...  6.083535  0.337323  0.717518   \n",
       "2559  1.000291  0.857970  1.323068  ...  6.083535  0.337323  0.717518   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.789394  1.730486  1.008250  0.711025  0.596827  1.678863  0.424949  \n",
       "1     0.789394  1.730486  1.008250  0.711025  0.596827  1.678863  0.424949  \n",
       "2     0.789394  1.730486  1.008250  0.711025  0.596827  1.678863  0.424949  \n",
       "3     0.789394  1.730486  1.008250  0.711025  0.596827  1.678863  0.424949  \n",
       "4     0.789394  1.730486  1.008250  0.711025  0.596827  1.678863  0.424949  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.228581  2.159327  1.279826  0.506622  0.282298  2.389439  0.408206  \n",
       "2556  0.228581  2.159327  1.279826  0.506622  0.282298  2.389439  0.408206  \n",
       "2557  0.228581  2.159327  1.279826  0.506622  0.282298  2.389439  0.408206  \n",
       "2558  0.228581  2.159327  1.279826  0.506622  0.282298  2.389439  0.408206  \n",
       "2559  0.228581  2.159327  1.279826  0.506622  0.282298  2.389439  0.408206  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070166</td>\n",
       "      <td>1.060305</td>\n",
       "      <td>0.308343</td>\n",
       "      <td>0.835856</td>\n",
       "      <td>0.636678</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.687164</td>\n",
       "      <td>1.028565</td>\n",
       "      <td>1.138698</td>\n",
       "      <td>0.257403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.746501</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.510457</td>\n",
       "      <td>0.789394</td>\n",
       "      <td>1.730486</td>\n",
       "      <td>1.008250</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.596827</td>\n",
       "      <td>1.678863</td>\n",
       "      <td>0.424949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070166</td>\n",
       "      <td>1.060305</td>\n",
       "      <td>0.308343</td>\n",
       "      <td>0.835856</td>\n",
       "      <td>0.636678</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.687164</td>\n",
       "      <td>1.028565</td>\n",
       "      <td>1.138698</td>\n",
       "      <td>0.257403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.746501</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.510457</td>\n",
       "      <td>0.789394</td>\n",
       "      <td>1.730486</td>\n",
       "      <td>1.008250</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.596827</td>\n",
       "      <td>1.678863</td>\n",
       "      <td>0.424949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070166</td>\n",
       "      <td>1.060305</td>\n",
       "      <td>0.308343</td>\n",
       "      <td>0.835856</td>\n",
       "      <td>0.636678</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.687164</td>\n",
       "      <td>1.028565</td>\n",
       "      <td>1.138698</td>\n",
       "      <td>0.257403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.746501</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.510457</td>\n",
       "      <td>0.789394</td>\n",
       "      <td>1.730486</td>\n",
       "      <td>1.008250</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.596827</td>\n",
       "      <td>1.678863</td>\n",
       "      <td>0.424949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070166</td>\n",
       "      <td>1.060305</td>\n",
       "      <td>0.308343</td>\n",
       "      <td>0.835856</td>\n",
       "      <td>0.636678</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.687164</td>\n",
       "      <td>1.028565</td>\n",
       "      <td>1.138698</td>\n",
       "      <td>0.257403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.746501</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.510457</td>\n",
       "      <td>0.789394</td>\n",
       "      <td>1.730486</td>\n",
       "      <td>1.008250</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.596827</td>\n",
       "      <td>1.678863</td>\n",
       "      <td>0.424949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070166</td>\n",
       "      <td>1.060305</td>\n",
       "      <td>0.308343</td>\n",
       "      <td>0.835856</td>\n",
       "      <td>0.636678</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.687164</td>\n",
       "      <td>1.028565</td>\n",
       "      <td>1.138698</td>\n",
       "      <td>0.257403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.746501</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.510457</td>\n",
       "      <td>0.789394</td>\n",
       "      <td>1.730486</td>\n",
       "      <td>1.008250</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.596827</td>\n",
       "      <td>1.678863</td>\n",
       "      <td>0.424949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.244119</td>\n",
       "      <td>0.542509</td>\n",
       "      <td>0.365433</td>\n",
       "      <td>1.300983</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>0.398248</td>\n",
       "      <td>1.000291</td>\n",
       "      <td>0.857970</td>\n",
       "      <td>1.323068</td>\n",
       "      <td>...</td>\n",
       "      <td>6.083535</td>\n",
       "      <td>0.337323</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>0.228581</td>\n",
       "      <td>2.159327</td>\n",
       "      <td>1.279826</td>\n",
       "      <td>0.506622</td>\n",
       "      <td>0.282298</td>\n",
       "      <td>2.389439</td>\n",
       "      <td>0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.244119</td>\n",
       "      <td>0.542509</td>\n",
       "      <td>0.365433</td>\n",
       "      <td>1.300983</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>0.398248</td>\n",
       "      <td>1.000291</td>\n",
       "      <td>0.857970</td>\n",
       "      <td>1.323068</td>\n",
       "      <td>...</td>\n",
       "      <td>6.083535</td>\n",
       "      <td>0.337323</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>0.228581</td>\n",
       "      <td>2.159327</td>\n",
       "      <td>1.279826</td>\n",
       "      <td>0.506622</td>\n",
       "      <td>0.282298</td>\n",
       "      <td>2.389439</td>\n",
       "      <td>0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.244119</td>\n",
       "      <td>0.542509</td>\n",
       "      <td>0.365433</td>\n",
       "      <td>1.300983</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>0.398248</td>\n",
       "      <td>1.000291</td>\n",
       "      <td>0.857970</td>\n",
       "      <td>1.323068</td>\n",
       "      <td>...</td>\n",
       "      <td>6.083535</td>\n",
       "      <td>0.337323</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>0.228581</td>\n",
       "      <td>2.159327</td>\n",
       "      <td>1.279826</td>\n",
       "      <td>0.506622</td>\n",
       "      <td>0.282298</td>\n",
       "      <td>2.389439</td>\n",
       "      <td>0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.244119</td>\n",
       "      <td>0.542509</td>\n",
       "      <td>0.365433</td>\n",
       "      <td>1.300983</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>0.398248</td>\n",
       "      <td>1.000291</td>\n",
       "      <td>0.857970</td>\n",
       "      <td>1.323068</td>\n",
       "      <td>...</td>\n",
       "      <td>6.083535</td>\n",
       "      <td>0.337323</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>0.228581</td>\n",
       "      <td>2.159327</td>\n",
       "      <td>1.279826</td>\n",
       "      <td>0.506622</td>\n",
       "      <td>0.282298</td>\n",
       "      <td>2.389439</td>\n",
       "      <td>0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.244119</td>\n",
       "      <td>0.542509</td>\n",
       "      <td>0.365433</td>\n",
       "      <td>1.300983</td>\n",
       "      <td>0.742717</td>\n",
       "      <td>0.264139</td>\n",
       "      <td>0.398248</td>\n",
       "      <td>1.000291</td>\n",
       "      <td>0.857970</td>\n",
       "      <td>1.323068</td>\n",
       "      <td>...</td>\n",
       "      <td>6.083535</td>\n",
       "      <td>0.337323</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>0.228581</td>\n",
       "      <td>2.159327</td>\n",
       "      <td>1.279826</td>\n",
       "      <td>0.506622</td>\n",
       "      <td>0.282298</td>\n",
       "      <td>2.389439</td>\n",
       "      <td>0.408206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Banda gamma\r\n",
    "df = pd.DataFrame(gamma_bands)\r\n",
    "gamma_df = df.transpose()\r\n",
    "gamma_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "gamma_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in gamma_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_gamma = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_gamma"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.296230  0.425451  0.276974  0.417305  0.571668  0.284168  0.424563   \n",
       "1     0.296230  0.425451  0.276974  0.417305  0.571668  0.284168  0.424563   \n",
       "2     0.296230  0.425451  0.276974  0.417305  0.571668  0.284168  0.424563   \n",
       "3     0.296230  0.425451  0.276974  0.417305  0.571668  0.284168  0.424563   \n",
       "4     0.296230  0.425451  0.276974  0.417305  0.571668  0.284168  0.424563   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.370961  0.449814  1.146706  3.372740  2.326301  0.212740  0.593154   \n",
       "2556  0.370961  0.449814  1.146706  3.372740  2.326301  0.212740  0.593154   \n",
       "2557  0.370961  0.449814  1.146706  3.372740  2.326301  0.212740  0.593154   \n",
       "2558  0.370961  0.449814  1.146706  3.372740  2.326301  0.212740  0.593154   \n",
       "2559  0.370961  0.449814  1.146706  3.372740  2.326301  0.212740  0.593154   \n",
       "\n",
       "            C3       CP1       CP5  ...         C4        T8       FC6  \\\n",
       "0     0.884798  0.792988  0.438355  ...   2.431686  0.295712  0.348758   \n",
       "1     0.884798  0.792988  0.438355  ...   2.431686  0.295712  0.348758   \n",
       "2     0.884798  0.792988  0.438355  ...   2.431686  0.295712  0.348758   \n",
       "3     0.884798  0.792988  0.438355  ...   2.431686  0.295712  0.348758   \n",
       "4     0.884798  0.792988  0.438355  ...   2.431686  0.295712  0.348758   \n",
       "...        ...       ...       ...  ...        ...       ...       ...   \n",
       "2555  1.589803  2.557764  3.804570  ...  17.305105  0.771617  1.971791   \n",
       "2556  1.589803  2.557764  3.804570  ...  17.305105  0.771617  1.971791   \n",
       "2557  1.589803  2.557764  3.804570  ...  17.305105  0.771617  1.971791   \n",
       "2558  1.589803  2.557764  3.804570  ...  17.305105  0.771617  1.971791   \n",
       "2559  1.589803  2.557764  3.804570  ...  17.305105  0.771617  1.971791   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.779843  1.044175  0.580807  0.359518  0.834561  0.960447  0.406656  \n",
       "1     0.779843  1.044175  0.580807  0.359518  0.834561  0.960447  0.406656  \n",
       "2     0.779843  1.044175  0.580807  0.359518  0.834561  0.960447  0.406656  \n",
       "3     0.779843  1.044175  0.580807  0.359518  0.834561  0.960447  0.406656  \n",
       "4     0.779843  1.044175  0.580807  0.359518  0.834561  0.960447  0.406656  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.788704  5.179255  3.076131  0.743108  0.665851  6.491435  1.554092  \n",
       "2556  0.788704  5.179255  3.076131  0.743108  0.665851  6.491435  1.554092  \n",
       "2557  0.788704  5.179255  3.076131  0.743108  0.665851  6.491435  1.554092  \n",
       "2558  0.788704  5.179255  3.076131  0.743108  0.665851  6.491435  1.554092  \n",
       "2559  0.788704  5.179255  3.076131  0.743108  0.665851  6.491435  1.554092  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.296230</td>\n",
       "      <td>0.425451</td>\n",
       "      <td>0.276974</td>\n",
       "      <td>0.417305</td>\n",
       "      <td>0.571668</td>\n",
       "      <td>0.284168</td>\n",
       "      <td>0.424563</td>\n",
       "      <td>0.884798</td>\n",
       "      <td>0.792988</td>\n",
       "      <td>0.438355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.431686</td>\n",
       "      <td>0.295712</td>\n",
       "      <td>0.348758</td>\n",
       "      <td>0.779843</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>0.580807</td>\n",
       "      <td>0.359518</td>\n",
       "      <td>0.834561</td>\n",
       "      <td>0.960447</td>\n",
       "      <td>0.406656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.296230</td>\n",
       "      <td>0.425451</td>\n",
       "      <td>0.276974</td>\n",
       "      <td>0.417305</td>\n",
       "      <td>0.571668</td>\n",
       "      <td>0.284168</td>\n",
       "      <td>0.424563</td>\n",
       "      <td>0.884798</td>\n",
       "      <td>0.792988</td>\n",
       "      <td>0.438355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.431686</td>\n",
       "      <td>0.295712</td>\n",
       "      <td>0.348758</td>\n",
       "      <td>0.779843</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>0.580807</td>\n",
       "      <td>0.359518</td>\n",
       "      <td>0.834561</td>\n",
       "      <td>0.960447</td>\n",
       "      <td>0.406656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.296230</td>\n",
       "      <td>0.425451</td>\n",
       "      <td>0.276974</td>\n",
       "      <td>0.417305</td>\n",
       "      <td>0.571668</td>\n",
       "      <td>0.284168</td>\n",
       "      <td>0.424563</td>\n",
       "      <td>0.884798</td>\n",
       "      <td>0.792988</td>\n",
       "      <td>0.438355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.431686</td>\n",
       "      <td>0.295712</td>\n",
       "      <td>0.348758</td>\n",
       "      <td>0.779843</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>0.580807</td>\n",
       "      <td>0.359518</td>\n",
       "      <td>0.834561</td>\n",
       "      <td>0.960447</td>\n",
       "      <td>0.406656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296230</td>\n",
       "      <td>0.425451</td>\n",
       "      <td>0.276974</td>\n",
       "      <td>0.417305</td>\n",
       "      <td>0.571668</td>\n",
       "      <td>0.284168</td>\n",
       "      <td>0.424563</td>\n",
       "      <td>0.884798</td>\n",
       "      <td>0.792988</td>\n",
       "      <td>0.438355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.431686</td>\n",
       "      <td>0.295712</td>\n",
       "      <td>0.348758</td>\n",
       "      <td>0.779843</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>0.580807</td>\n",
       "      <td>0.359518</td>\n",
       "      <td>0.834561</td>\n",
       "      <td>0.960447</td>\n",
       "      <td>0.406656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.296230</td>\n",
       "      <td>0.425451</td>\n",
       "      <td>0.276974</td>\n",
       "      <td>0.417305</td>\n",
       "      <td>0.571668</td>\n",
       "      <td>0.284168</td>\n",
       "      <td>0.424563</td>\n",
       "      <td>0.884798</td>\n",
       "      <td>0.792988</td>\n",
       "      <td>0.438355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.431686</td>\n",
       "      <td>0.295712</td>\n",
       "      <td>0.348758</td>\n",
       "      <td>0.779843</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>0.580807</td>\n",
       "      <td>0.359518</td>\n",
       "      <td>0.834561</td>\n",
       "      <td>0.960447</td>\n",
       "      <td>0.406656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.449814</td>\n",
       "      <td>1.146706</td>\n",
       "      <td>3.372740</td>\n",
       "      <td>2.326301</td>\n",
       "      <td>0.212740</td>\n",
       "      <td>0.593154</td>\n",
       "      <td>1.589803</td>\n",
       "      <td>2.557764</td>\n",
       "      <td>3.804570</td>\n",
       "      <td>...</td>\n",
       "      <td>17.305105</td>\n",
       "      <td>0.771617</td>\n",
       "      <td>1.971791</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>5.179255</td>\n",
       "      <td>3.076131</td>\n",
       "      <td>0.743108</td>\n",
       "      <td>0.665851</td>\n",
       "      <td>6.491435</td>\n",
       "      <td>1.554092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.449814</td>\n",
       "      <td>1.146706</td>\n",
       "      <td>3.372740</td>\n",
       "      <td>2.326301</td>\n",
       "      <td>0.212740</td>\n",
       "      <td>0.593154</td>\n",
       "      <td>1.589803</td>\n",
       "      <td>2.557764</td>\n",
       "      <td>3.804570</td>\n",
       "      <td>...</td>\n",
       "      <td>17.305105</td>\n",
       "      <td>0.771617</td>\n",
       "      <td>1.971791</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>5.179255</td>\n",
       "      <td>3.076131</td>\n",
       "      <td>0.743108</td>\n",
       "      <td>0.665851</td>\n",
       "      <td>6.491435</td>\n",
       "      <td>1.554092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.449814</td>\n",
       "      <td>1.146706</td>\n",
       "      <td>3.372740</td>\n",
       "      <td>2.326301</td>\n",
       "      <td>0.212740</td>\n",
       "      <td>0.593154</td>\n",
       "      <td>1.589803</td>\n",
       "      <td>2.557764</td>\n",
       "      <td>3.804570</td>\n",
       "      <td>...</td>\n",
       "      <td>17.305105</td>\n",
       "      <td>0.771617</td>\n",
       "      <td>1.971791</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>5.179255</td>\n",
       "      <td>3.076131</td>\n",
       "      <td>0.743108</td>\n",
       "      <td>0.665851</td>\n",
       "      <td>6.491435</td>\n",
       "      <td>1.554092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.449814</td>\n",
       "      <td>1.146706</td>\n",
       "      <td>3.372740</td>\n",
       "      <td>2.326301</td>\n",
       "      <td>0.212740</td>\n",
       "      <td>0.593154</td>\n",
       "      <td>1.589803</td>\n",
       "      <td>2.557764</td>\n",
       "      <td>3.804570</td>\n",
       "      <td>...</td>\n",
       "      <td>17.305105</td>\n",
       "      <td>0.771617</td>\n",
       "      <td>1.971791</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>5.179255</td>\n",
       "      <td>3.076131</td>\n",
       "      <td>0.743108</td>\n",
       "      <td>0.665851</td>\n",
       "      <td>6.491435</td>\n",
       "      <td>1.554092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.370961</td>\n",
       "      <td>0.449814</td>\n",
       "      <td>1.146706</td>\n",
       "      <td>3.372740</td>\n",
       "      <td>2.326301</td>\n",
       "      <td>0.212740</td>\n",
       "      <td>0.593154</td>\n",
       "      <td>1.589803</td>\n",
       "      <td>2.557764</td>\n",
       "      <td>3.804570</td>\n",
       "      <td>...</td>\n",
       "      <td>17.305105</td>\n",
       "      <td>0.771617</td>\n",
       "      <td>1.971791</td>\n",
       "      <td>0.788704</td>\n",
       "      <td>5.179255</td>\n",
       "      <td>3.076131</td>\n",
       "      <td>0.743108</td>\n",
       "      <td>0.665851</td>\n",
       "      <td>6.491435</td>\n",
       "      <td>1.554092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df_labels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\r\n",
    "rows = list()\r\n",
    "for _,row in dfLabels.iterrows():\r\n",
    "    rows += [row]*64\r\n",
    "aux_labels = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      valence  arousal  dominance  liking\n",
       "0        8.13     4.83        9.0    4.87\n",
       "1        8.13     4.83        9.0    4.87\n",
       "2        8.13     4.83        9.0    4.87\n",
       "3        8.13     4.83        9.0    4.87\n",
       "4        8.13     4.83        9.0    4.87\n",
       "...       ...      ...        ...     ...\n",
       "2555     7.15     4.03        9.0    1.88\n",
       "2556     7.15     4.03        9.0    1.88\n",
       "2557     7.15     4.03        9.0    1.88\n",
       "2558     7.15     4.03        9.0    1.88\n",
       "2559     7.15     4.03        9.0    1.88\n",
       "\n",
       "[2560 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>liking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.13</td>\n",
       "      <td>4.83</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.13</td>\n",
       "      <td>4.83</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.13</td>\n",
       "      <td>4.83</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.13</td>\n",
       "      <td>4.83</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.13</td>\n",
       "      <td>4.83</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>7.15</td>\n",
       "      <td>4.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>7.15</td>\n",
       "      <td>4.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>7.15</td>\n",
       "      <td>4.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>7.15</td>\n",
       "      <td>4.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>7.15</td>\n",
       "      <td>4.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data_delta = aux_delta.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_theta = aux_theta.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_alpha = aux_alpha.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_beta = aux_beta.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_gamma = aux_gamma.merge(aux_labels, left_index=True, right_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data = data_delta.drop(['arousal', 'dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia[['valence']]\r\n",
    "\r\n",
    "x = copia.drop(columns=['valence'])\r\n",
    "\r\n",
    "    # test_size = 0.2 --> 80% datos para entrenamiento, 20% para test\r\n",
    "    # max_depth --> The deeper the tree, the more splits it has and it captures more information about the data. En este modelo, valores altos de max_depths tienden a 'overfit' los datos, lo comprobamos en el siguiente bloque\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "\r\n",
    "accuracy_score(yTest, predict)*100\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "svm_clf = svm.SVC(kernel='linear')\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_delta = accuracy_score(yTest, predict)\r\n",
    "svm_acc_delta = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_delta = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_delta = precision_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_prec_sad_delta = precision_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_prec_happy_delta = precision_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_prec_sad_delta = precision_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_prec_happy_delta = precision_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_prec_sad_delta = precision_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_delta = recall_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_rec_sad_delta = recall_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_rec_happy_delta = recall_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_rec_sad_delta = recall_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_rec_happy_delta = recall_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_rec_sad_delta = recall_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_delta = f1_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_f1_sad_delta = f1_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_f1_happy_delta = f1_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_f1_sad_delta = f1_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_f1_happy_delta = f1_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_f1_sad_delta = f1_score(yTest, knn_predict, pos_label=\"sad\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-14-7eb869df1f7e>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xTrain, yTrain)\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label. It should be one of ['happy', 'sad']",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7eb869df1f7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[0mrf_prec_happy_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"happy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mrf_prec_sad_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sad\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1655\u001b[0m     \"\"\"\n\u001b[1;32m-> 1656\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1657\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1465\u001b[0m                                     pos_label)\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1283\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m   1286\u001b[0m                         \u001b[1;34mf\"pos_label={pos_label} is not a valid label. It \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m                         \u001b[1;34mf\"should be one of {present_labels}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: pos_label=1 is not a valid label. It should be one of ['happy', 'sad']"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_theta.drop(['arousal', 'dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia[['valence']]\r\n",
    "\r\n",
    "x = copia.drop(columns=['valence'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "svm_clf = svm.SVC(kernel='linear')\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_theta = accuracy_score(yTest, predict)\r\n",
    "svm_acc_theta = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_theta = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_theta = precision_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_prec_sad_theta = precision_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_prec_happy_theta = precision_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_prec_sad_theta = precision_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_prec_happy_theta = precision_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_prec_sad_theta = precision_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_theta = recall_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_rec_sad_theta = recall_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_rec_happy_theta = recall_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_rec_sad_theta = recall_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_rec_happy_theta = recall_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_rec_sad_theta = recall_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_theta = f1_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_f1_sad_theta = f1_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_f1_happy_theta = f1_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_f1_sad_theta = f1_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_f1_happy_theta = f1_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_f1_sad_theta = f1_score(yTest, knn_predict, pos_label=\"sad\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-585-c9efdd9f3716>:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xTrain, yTrain)\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_alpha.drop(['arousal', 'dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia[['valence']]\r\n",
    "\r\n",
    "x = copia.drop(columns=['valence'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "svm_clf = svm.SVC(kernel='linear')\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_alpha = accuracy_score(yTest, predict)\r\n",
    "svm_acc_alpha = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_alpha = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_alpha = precision_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_prec_sad_alpha = precision_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_prec_happy_alpha = precision_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_prec_sad_alpha = precision_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_prec_happy_alpha = precision_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_prec_sad_alpha = precision_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_alpha = recall_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_rec_sad_alpha = recall_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_rec_happy_alpha = recall_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_rec_sad_alpha = recall_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_rec_happy_alpha = recall_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_rec_sad_alpha = recall_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_alpha = f1_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_f1_sad_alpha = f1_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_f1_happy_alpha = f1_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_f1_sad_alpha = f1_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_f1_happy_alpha = f1_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_f1_sad_alpha = f1_score(yTest, knn_predict, pos_label=\"sad\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-586-ffeff3b83b4f>:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xTrain, yTrain)\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_beta.drop(['arousal', 'dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia[['valence']]\r\n",
    "\r\n",
    "x = copia.drop(columns=['valence'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "svm_clf = svm.SVC(kernel='linear')\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_beta = accuracy_score(yTest, predict)\r\n",
    "svm_acc_beta = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_beta = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_beta = precision_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_prec_sad_beta = precision_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_prec_happy_beta = precision_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_prec_sad_beta = precision_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_prec_happy_beta = precision_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_prec_sad_beta = precision_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_beta = recall_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_rec_sad_beta = recall_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_rec_happy_beta = recall_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_rec_sad_beta = recall_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_rec_happy_beta = recall_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_rec_sad_beta = recall_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_beta = f1_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_f1_sad_beta = f1_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_f1_happy_beta = f1_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_f1_sad_beta = f1_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_f1_happy_beta = f1_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_f1_sad_beta = f1_score(yTest, knn_predict, pos_label=\"sad\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-587-53fc42e707fc>:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xTrain, yTrain)\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_gamma.drop(['arousal', 'dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia[['valence']]\r\n",
    "\r\n",
    "x = copia.drop(columns=['valence'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "svm_clf = svm.SVC(kernel='linear')\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_gamma = accuracy_score(yTest, predict)\r\n",
    "svm_acc_gamma = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_gamma = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_gamma = precision_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_prec_sad_gamma = precision_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_prec_happy_gamma = precision_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_prec_sad_gamma = precision_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_prec_happy_gamma = precision_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_prec_sad_gamma = precision_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_gamma = recall_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_rec_sad_gamma = recall_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_rec_happy_gamma = recall_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_rec_sad_gamma= recall_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_rec_happy_gamma = recall_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_rec_sad_gamma = recall_score(yTest, knn_predict, pos_label=\"sad\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_gamma = f1_score(yTest, predict, pos_label=\"happy\")\r\n",
    "rf_f1_sad_gamma = f1_score(yTest, predict, pos_label=\"sad\")\r\n",
    "svm_f1_happy_gamma = f1_score(yTest, svm_predict, pos_label=\"happy\")\r\n",
    "svm_f1_sad_gamma = f1_score(yTest, svm_predict, pos_label=\"sad\")\r\n",
    "knn_f1_happy_gamma = f1_score(yTest, knn_predict, pos_label=\"happy\")\r\n",
    "knn_f1_sad_gamma = f1_score(yTest, knn_predict, pos_label=\"sad\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-588-7512fdf33a18>:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xTrain, yTrain)\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "col_names = ['Subject',\r\n",
    "             'Experiment ID',\r\n",
    "             'Feature extraction',\r\n",
    "             'Band selection',\r\n",
    "             'Channel selection',\r\n",
    "             'Classification algorithm',\r\n",
    "             'Accuracy',\r\n",
    "             'Happy precision',\r\n",
    "             'Sad precision',\r\n",
    "             'Happy recall',\r\n",
    "             'Sad recall',\r\n",
    "             'Happy f1-score',\r\n",
    "             'Sad f1-score']\r\n",
    "\r\n",
    "data_CSV = [subject_id, 2, \"STFT\", \"Delta\", \"-\", \"Random Forest\", rf_acc_delta, rf_prec_happy_delta, rf_prec_sad_delta, rf_rec_happy_delta, rf_rec_sad_delta, rf_f1_happy_delta, rf_f1_sad_delta], [subject_id, 2, \"STFT\", \"Delta\", \"-\", \"SVM\", svm_acc_delta, svm_prec_happy_delta, svm_prec_sad_delta, svm_rec_happy_delta, svm_rec_sad_delta, svm_f1_happy_delta, svm_f1_sad_delta], [subject_id, 2, \"STFT\", \"Delta\", \"-\", \"kNN\", knn_acc_delta, knn_prec_happy_delta, knn_prec_sad_delta, knn_rec_happy_delta, knn_rec_sad_delta, knn_f1_happy_delta, knn_f1_sad_delta], [subject_id, 2, \"STFT\", \"Theta\", \"-\", \"Random Forest\", rf_acc_theta, rf_prec_happy_theta, rf_prec_sad_theta, rf_rec_happy_theta, rf_rec_sad_theta, rf_f1_happy_theta, rf_f1_sad_theta], [subject_id, 2, \"STFT\", \"Theta\", \"-\", \"SVM\", svm_acc_theta, svm_prec_happy_theta, svm_prec_sad_theta, svm_rec_happy_theta, svm_rec_sad_theta, svm_f1_happy_theta, svm_f1_sad_theta], [subject_id, 2, \"STFT\", \"Theta\", \"-\", \"kNN\", knn_acc_theta, knn_prec_happy_theta, knn_prec_sad_theta, knn_rec_happy_theta, knn_rec_sad_theta, knn_f1_happy_theta, knn_f1_sad_theta], [subject_id, 2, \"STFT\", \"Alpha\", \"-\", \"Random Forest\", rf_acc_alpha, rf_prec_happy_alpha, rf_prec_sad_alpha, rf_rec_happy_alpha, rf_rec_sad_alpha, rf_f1_happy_alpha, rf_f1_sad_alpha], [subject_id, 2, \"STFT\", \"Alpha\", \"-\", \"SVM\", svm_acc_alpha, svm_prec_happy_alpha, svm_prec_sad_alpha, svm_rec_happy_alpha, svm_rec_sad_alpha, svm_f1_happy_alpha, svm_f1_sad_alpha], [subject_id, 2, \"STFT\", \"Alpha\", \"-\", \"kNN\", knn_acc_alpha, knn_prec_happy_alpha, knn_prec_sad_alpha, knn_rec_happy_alpha, knn_rec_sad_alpha, knn_f1_happy_alpha, knn_f1_sad_alpha], [subject_id, 2, \"STFT\", \"Beta\", \"-\", \"Random Forest\", rf_acc_beta, rf_prec_happy_beta, rf_prec_sad_beta, rf_rec_happy_beta, rf_rec_sad_beta, rf_f1_happy_beta, rf_f1_sad_beta], [subject_id, 2, \"STFT\", \"Beta\", \"-\", \"SVM\", svm_acc_beta, svm_prec_happy_beta, svm_prec_sad_beta, svm_rec_happy_beta, svm_rec_sad_beta, svm_f1_happy_beta, svm_f1_sad_beta], [subject_id, 2, \"STFT\", \"Beta\", \"-\", \"kNN\", knn_acc_beta, knn_prec_happy_beta, knn_prec_sad_beta, knn_rec_happy_beta, knn_rec_sad_beta, knn_f1_happy_beta, knn_f1_sad_beta], [subject_id, 2, \"STFT\", \"Gamma\", \"-\", \"Random Forest\", rf_acc_gamma, rf_prec_happy_gamma, rf_prec_sad_gamma, rf_rec_happy_gamma, rf_rec_sad_gamma, rf_f1_happy_gamma, rf_f1_sad_gamma], [subject_id, 2, \"STFT\", \"Gamma\", \"-\", \"SVM\", svm_acc_gamma, svm_prec_happy_gamma, svm_prec_sad_gamma, svm_rec_happy_gamma, svm_rec_sad_gamma, svm_f1_happy_gamma, svm_f1_sad_gamma], [subject_id, 2, \"STFT\", \"Gamma\", \"-\", \"kNN\", knn_acc_gamma, knn_prec_happy_gamma, knn_prec_sad_gamma, knn_rec_happy_gamma, knn_rec_sad_gamma, knn_f1_happy_gamma, knn_f1_sad_gamma]\r\n",
    "all_data = data_CSV\r\n",
    "\r\n",
    "csv_df = pd.DataFrame(all_data, columns=col_names)\r\n",
    "\r\n",
    "csv_df.to_csv(\"experiment2_1.csv\", mode=\"a\", header=False, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}