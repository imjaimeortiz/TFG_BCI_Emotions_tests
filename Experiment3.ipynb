{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             FP1        AF3        F7        F3       FC1        FC5  \\\n",
       "0       0.948232  10.260175  1.013050 -7.658428 -1.811108  11.011411   \n",
       "1       1.653335  12.795443 -1.067832 -3.267558 -4.783876   7.402976   \n",
       "2       3.013726  10.426192  3.908249  0.701542 -0.522649   1.120469   \n",
       "3       1.495061   8.229207  6.094405  2.959722  1.299854  -0.832024   \n",
       "4      -1.264836   3.751782  4.145906  3.459897 -0.916779  -0.784404   \n",
       "...          ...        ...       ...       ...       ...        ...   \n",
       "322555 -0.097608  -0.062015 -0.151092  0.013060 -0.046585  -0.060403   \n",
       "322556 -0.097608  -0.062015 -0.151092  0.013060 -0.046585  -0.060403   \n",
       "322557 -0.097608  -0.062015 -0.151092  0.013060 -0.046585  -0.060403   \n",
       "322558 -0.097608  -0.062015 -0.151092  0.013060 -0.046585  -0.060403   \n",
       "322559 -0.097608  -0.062015 -0.151092  0.013060 -0.046585  -0.060403   \n",
       "\n",
       "              T7        C3       CP1        CP5  ...        F4        F8  \\\n",
       "0       3.026008 -2.380048  3.978952  -9.657708  ...  4.239575  4.888393   \n",
       "1       2.676232 -3.614201 -1.434440  -0.906298  ...  4.557239  6.007259   \n",
       "2       2.046996 -4.286566 -6.174767   9.408599  ...  0.636801  2.921478   \n",
       "3       2.192056 -5.170547 -6.571542  14.101073  ... -2.965047 -0.679860   \n",
       "4      -4.694002 -5.332026 -7.793136  16.284187  ...  3.248115 -1.103246   \n",
       "...          ...       ...       ...        ...  ...       ...       ...   \n",
       "322555  0.149920  0.000826  0.214036  -0.050429  ... -0.101962  0.036677   \n",
       "322556  0.149920  0.000826  0.215036  -0.050429  ... -0.101962  0.036677   \n",
       "322557  0.149920  0.000826  0.215036  -0.050429  ... -0.101962  0.036677   \n",
       "322558  0.149920  0.000826  0.214036  -0.050429  ... -0.101962  0.036677   \n",
       "322559  0.149920  0.000826  0.215036  -0.050429  ... -0.101962  0.036677   \n",
       "\n",
       "             AF4       Fp2        Fz         Cz  valence  arousal  dominance  \\\n",
       "0       0.596471  0.589618 -2.276449  -0.109300     7.71     7.60       6.90   \n",
       "1      -1.881391 -4.831903 -1.739787  -6.518661     7.71     7.60       6.90   \n",
       "2      -4.484906 -8.186728  0.555901 -11.727187     7.71     7.60       6.90   \n",
       "3      -4.483488 -7.905437 -1.168129  -9.051847     7.71     7.60       6.90   \n",
       "4      -2.547386 -4.419073 -1.319219  -4.072682     7.71     7.60       6.90   \n",
       "...          ...       ...       ...        ...      ...      ...        ...   \n",
       "322555 -0.007930  0.081379 -0.081538  -0.009341     5.10     7.12       6.17   \n",
       "322556 -0.007930  0.081379 -0.081538  -0.009341     5.10     7.12       6.17   \n",
       "322557 -0.007930  0.081379 -0.082538  -0.009341     5.10     7.12       6.17   \n",
       "322558 -0.007930  0.081379 -0.081538  -0.009341     5.10     7.12       6.17   \n",
       "322559 -0.007930  0.081379 -0.082538  -0.009341     5.10     7.12       6.17   \n",
       "\n",
       "        liking  \n",
       "0         7.83  \n",
       "1         7.83  \n",
       "2         7.83  \n",
       "3         7.83  \n",
       "4         7.83  \n",
       "...        ...  \n",
       "322555    5.97  \n",
       "322556    5.97  \n",
       "322557    5.97  \n",
       "322558    5.97  \n",
       "322559    5.97  \n",
       "\n",
       "[322560 rows x 36 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FP1</th>\n      <th>AF3</th>\n      <th>F7</th>\n      <th>F3</th>\n      <th>FC1</th>\n      <th>FC5</th>\n      <th>T7</th>\n      <th>C3</th>\n      <th>CP1</th>\n      <th>CP5</th>\n      <th>...</th>\n      <th>F4</th>\n      <th>F8</th>\n      <th>AF4</th>\n      <th>Fp2</th>\n      <th>Fz</th>\n      <th>Cz</th>\n      <th>valence</th>\n      <th>arousal</th>\n      <th>dominance</th>\n      <th>liking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.948232</td>\n      <td>10.260175</td>\n      <td>1.013050</td>\n      <td>-7.658428</td>\n      <td>-1.811108</td>\n      <td>11.011411</td>\n      <td>3.026008</td>\n      <td>-2.380048</td>\n      <td>3.978952</td>\n      <td>-9.657708</td>\n      <td>...</td>\n      <td>4.239575</td>\n      <td>4.888393</td>\n      <td>0.596471</td>\n      <td>0.589618</td>\n      <td>-2.276449</td>\n      <td>-0.109300</td>\n      <td>7.71</td>\n      <td>7.60</td>\n      <td>6.90</td>\n      <td>7.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.653335</td>\n      <td>12.795443</td>\n      <td>-1.067832</td>\n      <td>-3.267558</td>\n      <td>-4.783876</td>\n      <td>7.402976</td>\n      <td>2.676232</td>\n      <td>-3.614201</td>\n      <td>-1.434440</td>\n      <td>-0.906298</td>\n      <td>...</td>\n      <td>4.557239</td>\n      <td>6.007259</td>\n      <td>-1.881391</td>\n      <td>-4.831903</td>\n      <td>-1.739787</td>\n      <td>-6.518661</td>\n      <td>7.71</td>\n      <td>7.60</td>\n      <td>6.90</td>\n      <td>7.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.013726</td>\n      <td>10.426192</td>\n      <td>3.908249</td>\n      <td>0.701542</td>\n      <td>-0.522649</td>\n      <td>1.120469</td>\n      <td>2.046996</td>\n      <td>-4.286566</td>\n      <td>-6.174767</td>\n      <td>9.408599</td>\n      <td>...</td>\n      <td>0.636801</td>\n      <td>2.921478</td>\n      <td>-4.484906</td>\n      <td>-8.186728</td>\n      <td>0.555901</td>\n      <td>-11.727187</td>\n      <td>7.71</td>\n      <td>7.60</td>\n      <td>6.90</td>\n      <td>7.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.495061</td>\n      <td>8.229207</td>\n      <td>6.094405</td>\n      <td>2.959722</td>\n      <td>1.299854</td>\n      <td>-0.832024</td>\n      <td>2.192056</td>\n      <td>-5.170547</td>\n      <td>-6.571542</td>\n      <td>14.101073</td>\n      <td>...</td>\n      <td>-2.965047</td>\n      <td>-0.679860</td>\n      <td>-4.483488</td>\n      <td>-7.905437</td>\n      <td>-1.168129</td>\n      <td>-9.051847</td>\n      <td>7.71</td>\n      <td>7.60</td>\n      <td>6.90</td>\n      <td>7.83</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.264836</td>\n      <td>3.751782</td>\n      <td>4.145906</td>\n      <td>3.459897</td>\n      <td>-0.916779</td>\n      <td>-0.784404</td>\n      <td>-4.694002</td>\n      <td>-5.332026</td>\n      <td>-7.793136</td>\n      <td>16.284187</td>\n      <td>...</td>\n      <td>3.248115</td>\n      <td>-1.103246</td>\n      <td>-2.547386</td>\n      <td>-4.419073</td>\n      <td>-1.319219</td>\n      <td>-4.072682</td>\n      <td>7.71</td>\n      <td>7.60</td>\n      <td>6.90</td>\n      <td>7.83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>322555</th>\n      <td>-0.097608</td>\n      <td>-0.062015</td>\n      <td>-0.151092</td>\n      <td>0.013060</td>\n      <td>-0.046585</td>\n      <td>-0.060403</td>\n      <td>0.149920</td>\n      <td>0.000826</td>\n      <td>0.214036</td>\n      <td>-0.050429</td>\n      <td>...</td>\n      <td>-0.101962</td>\n      <td>0.036677</td>\n      <td>-0.007930</td>\n      <td>0.081379</td>\n      <td>-0.081538</td>\n      <td>-0.009341</td>\n      <td>5.10</td>\n      <td>7.12</td>\n      <td>6.17</td>\n      <td>5.97</td>\n    </tr>\n    <tr>\n      <th>322556</th>\n      <td>-0.097608</td>\n      <td>-0.062015</td>\n      <td>-0.151092</td>\n      <td>0.013060</td>\n      <td>-0.046585</td>\n      <td>-0.060403</td>\n      <td>0.149920</td>\n      <td>0.000826</td>\n      <td>0.215036</td>\n      <td>-0.050429</td>\n      <td>...</td>\n      <td>-0.101962</td>\n      <td>0.036677</td>\n      <td>-0.007930</td>\n      <td>0.081379</td>\n      <td>-0.081538</td>\n      <td>-0.009341</td>\n      <td>5.10</td>\n      <td>7.12</td>\n      <td>6.17</td>\n      <td>5.97</td>\n    </tr>\n    <tr>\n      <th>322557</th>\n      <td>-0.097608</td>\n      <td>-0.062015</td>\n      <td>-0.151092</td>\n      <td>0.013060</td>\n      <td>-0.046585</td>\n      <td>-0.060403</td>\n      <td>0.149920</td>\n      <td>0.000826</td>\n      <td>0.215036</td>\n      <td>-0.050429</td>\n      <td>...</td>\n      <td>-0.101962</td>\n      <td>0.036677</td>\n      <td>-0.007930</td>\n      <td>0.081379</td>\n      <td>-0.082538</td>\n      <td>-0.009341</td>\n      <td>5.10</td>\n      <td>7.12</td>\n      <td>6.17</td>\n      <td>5.97</td>\n    </tr>\n    <tr>\n      <th>322558</th>\n      <td>-0.097608</td>\n      <td>-0.062015</td>\n      <td>-0.151092</td>\n      <td>0.013060</td>\n      <td>-0.046585</td>\n      <td>-0.060403</td>\n      <td>0.149920</td>\n      <td>0.000826</td>\n      <td>0.214036</td>\n      <td>-0.050429</td>\n      <td>...</td>\n      <td>-0.101962</td>\n      <td>0.036677</td>\n      <td>-0.007930</td>\n      <td>0.081379</td>\n      <td>-0.081538</td>\n      <td>-0.009341</td>\n      <td>5.10</td>\n      <td>7.12</td>\n      <td>6.17</td>\n      <td>5.97</td>\n    </tr>\n    <tr>\n      <th>322559</th>\n      <td>-0.097608</td>\n      <td>-0.062015</td>\n      <td>-0.151092</td>\n      <td>0.013060</td>\n      <td>-0.046585</td>\n      <td>-0.060403</td>\n      <td>0.149920</td>\n      <td>0.000826</td>\n      <td>0.215036</td>\n      <td>-0.050429</td>\n      <td>...</td>\n      <td>-0.101962</td>\n      <td>0.036677</td>\n      <td>-0.007930</td>\n      <td>0.081379</td>\n      <td>-0.082538</td>\n      <td>-0.009341</td>\n      <td>5.10</td>\n      <td>7.12</td>\n      <td>6.17</td>\n      <td>5.97</td>\n    </tr>\n  </tbody>\n</table>\n<p>322560 rows × 36 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "files = os.listdir('d\\\\')\n",
    "\n",
    "list_of_dfs = []\n",
    "for file in files:\n",
    "    with open(os.path.join('d\\\\',file), 'rb') as pickle_file:\n",
    "        dictRaw = pd.read_pickle(pickle_file) \n",
    "        labels = dictRaw.get('labels')\n",
    "        data = dictRaw.get('data')\n",
    "        \n",
    "        dfLabels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\n",
    "\n",
    "        a,b,c = data.shape\n",
    "        E = data.reshape(40, 322560)\n",
    "        allData = pd.DataFrame(E).transpose()\n",
    "        rows = list()\n",
    "        for _,row in dfLabels.iterrows():\n",
    "            rows += [row]*8064\n",
    "        aux = pd.DataFrame(rows).reset_index(drop=True)\n",
    "        allData = allData.merge(aux, left_index=True, right_index=True)\n",
    "        \n",
    "        list_of_dfs.append(allData)\n",
    "data = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature','valence', 'arousal', 'dominance', 'liking']\n",
    "\n",
    "data.drop(['hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature'],axis = 'columns', inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#def select_file(file):\n",
    "    #Lectura mediante pandas\n",
    "dictRaw = pd.read_pickle('d\\\\s01.dat')\n",
    "\n",
    "labels = dictRaw.get('labels')\n",
    "\n",
    "dfLabels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\n",
    "\n",
    "data = dictRaw.get('data')\n",
    "\n",
    "df_videos = {}\n",
    "    #Recorrido de cada una de las columnas de la tabla 3d, y guardado en una una lista de dataframes para cada uno de los videos.\n",
    "for i in range(40):\n",
    "    df_videos[i] = pd.DataFrame(data[i])\n",
    "    df_videos[i] = df_videos[i].transpose()\n",
    "    df_videos[i].columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature']\n",
    "    df_videos[i].drop(['hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature'],axis = 'columns', inplace=True)\n",
    "df_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-19-4fd5bce52db8>:5: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  y = copia[['valence']]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4fd5bce52db8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcopia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopia\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "copia = data.copy()\n",
    "\n",
    "y = copia[['valence']]\n",
    "\n",
    "x = copia.drop(columns=['valence'])\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Frecuencia de muestreo\n",
    "    fs = 128\n",
    "    # Window\n",
    "    window = \"hann\"\n",
    "    # Length of each segment\n",
    "    # nperseg = 256 por defecto\n",
    "    # noverlap\n",
    "    # Por defecto a None, if None : noverlap = nperseg / 2\n",
    "    # [...]\n",
    "\n",
    "    # Definicion de bandas\n",
    "    eeg_bands = {'Delta': (1, 4),\n",
    "                'Theta': (4, 8),\n",
    "                'Alpha': (8, 14),\n",
    "                'Beta': (14, 30),\n",
    "                'Gamma': (30, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOURIER\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "# SE COGE EL PRIMER VÍDEOS, Df_VIDEOS[0]\n",
    "def do_stft(video, channel):\n",
    "    # Array \n",
    "    x = df_videos[video][channel]\n",
    "\n",
    "    # Array of the sample frequency, Array of the segment times, STFT of x\n",
    "    f, t , Zxx = scipy.signal.stft(x, fs, window)\n",
    "\n",
    "    #print(np.abs(Zxx))\n",
    "    '''\n",
    "    plt.pcolormesh(t, f, np.abs(Zxx), vmin=0, shading='gouraud')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()\n",
    "    '''\n",
    "    return Zxx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARACION EN LAS DISTINTAS BANDAS DE FRECUENCIA\n",
    "\n",
    "def make_bands(Zxx):\n",
    "    #Obtener valores reales de STFT, solo positivos.\n",
    "    values = np.absolute(Zxx)\n",
    "\n",
    "    # Get frequencies for amplitudes in Hz\n",
    "    fft_freq = np.fft.rfftfreq(len(data), 1.0/fs)\n",
    "    #print(fft_freq)\n",
    "\n",
    "    # Obtención de cada una de las bandas de frecuencia\n",
    "    eeg_band_fft = dict()\n",
    "    for band in eeg_bands:  \n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq <= eeg_bands[band][1]))[0]\n",
    "        eeg_band_fft[band] = values[freq_ix]\n",
    "\n",
    "    #print(eeg_band_fft)\n",
    "    '''\n",
    "    eeg_band_fft_means = dict()\n",
    "    for band in eeg_bands:  \n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq <= eeg_bands[band][1]))[0]\n",
    "        eeg_band_fft_means[band] = np.mean(values[freq_ix])\n",
    "\n",
    "    #print(eeg_band_fft_means)\n",
    "\n",
    "    #Graficación de las medias de los datos\n",
    "    df = pd.DataFrame(columns=['band', 'val'])\n",
    "    df['band'] = eeg_bands.keys()\n",
    "    df['val'] = [eeg_band_fft_means[band] for band in eeg_bands]\n",
    "    ax = df.plot.bar(x='band', y='val', legend=False)\n",
    "    ax.set_xlabel(\"EEG band\")\n",
    "    ax.set_ylabel(\"Mean band Amplitude\")\n",
    "    '''\n",
    "    #print(df)\n",
    "\n",
    "    #print(\"\\n\\n\")\n",
    "\n",
    "    '''\n",
    "    print(\"Shape de Zxx: \", Zxx.shape)\n",
    "    print(\"Shape de Delta: \", eeg_band_fft['Delta'].shape)\n",
    "    print(\"Shape de Theta: \", eeg_band_fft['Theta'].shape)\n",
    "    print(\"Shape de Alpha: \", eeg_band_fft['Alpha'].shape)\n",
    "    print(\"Shape de Beta: \", eeg_band_fft['Beta'].shape)\n",
    "    print(\"Shape de Gamma: \", eeg_band_fft['Gamma'].shape)\n",
    "    '''\n",
    "    return eeg_band_fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora hay que hacer las medias sobre cada banda de frecuencia. La media entre cada una de las posiciones de los bloques. Hacer la media entre todas las posiciones 0, 1, 2... 63 de cada uno de los bloques\n",
    "import numpy as np\n",
    "\n",
    "def channel_freq(eeg_band_fft):\n",
    "        \n",
    "        freq = np.zeros((5, 64))        # 5 bandas, 64 posiciones de los datos\n",
    "\n",
    "        # Se va a recorrer {Delta, Theta, Alpha, Beta, Gamma}\n",
    "        for band in eeg_bands:\n",
    "\n",
    "                # Para cada una de las 64 posiciones del array\n",
    "                for j in range (0, 64):\n",
    "                        \n",
    "                        val = []\n",
    "                        # Se va a recorrer cada uno de los arrays que hay en cada una de las bandas\n",
    "                        for i in range (0, len(eeg_band_fft[band])):\n",
    "                                val.append(eeg_band_fft[band][i][j])\n",
    "                                # Ejemplo : eeg_band_fft['Delta'][0][0*0 + 0]\n",
    "                        if (band == \"Delta\"):\n",
    "                                freq[0][j] = np.mean(val)\n",
    "                        elif (band == \"Theta\"):\n",
    "                                freq[1][j] = np.mean(val)\n",
    "                        elif (band == \"Alpha\"):\n",
    "                                freq[2][j] = np.mean(val)\n",
    "                        elif (band == \"Beta\"):\n",
    "                                freq[3][j] = np.mean(val)\n",
    "                        elif (band == \"Gamma\"):\n",
    "                                freq[4][j] = np.mean(val)\n",
    "        return(freq)     # En freq tenemos las frecuencias medias de cada una de las bandas\n",
    "\n",
    "# Recordamos : Estamos tratando los datos relativos al video 0, un canal concreto de un sujeto concreto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2d58e180b762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'FP1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AF3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'T7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Pz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PO3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Oz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PO4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'T8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AF4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Fp2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Fz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Cz'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mZxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_stft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0meeg_band_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_bands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-67ee6aac8824>\u001b[0m in \u001b[0;36mdo_stft\u001b[1;34m(video, channel)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdo_stft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Array of the sample frequency, Array of the segment times, STFT of x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#df_file_videos = select_file('d\\\\s01.dat')\n",
    "# Obtener la división por bandas de frecuencia de cada uno de los canales del video 0\n",
    "for video in range(0, 40):\n",
    "    delta_bands = []\n",
    "    theta_bands = []\n",
    "    beta_bands = []\n",
    "    alpha_bands = []\n",
    "    gamma_bands = []\n",
    "\n",
    "    for channel in ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']:\n",
    "        Zxx = do_stft(video, channel)\n",
    "        eeg_band_fft = make_bands(Zxx)\n",
    "        print(video)\n",
    "        print(\"\\n\")\n",
    "        print(channel)\n",
    "        freq = channel_freq(eeg_band_fft)\n",
    "\n",
    "        delta_bands.append(freq[0])\n",
    "        theta_bands.append(freq[1])\n",
    "        alpha_bands.append(freq[2])\n",
    "        beta_bands.append(freq[3])\n",
    "        gamma_bands.append(freq[4])\n",
    "        \n",
    "        print(freq[0])\n",
    "        print(\"\\n\\n\")\n",
    "    # En freq tenemos la media de todas las bandas de frecuencia de cada uno de los canales del vídeo 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banda delta\n",
    "df = pd.DataFrame(delta_bands)\n",
    "delta_df = df.transpose()\n",
    "delta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\n",
    "delta_df\n",
    "\n",
    "rows = list()\n",
    "for _,row in delta_df.iterrows():\n",
    "    rows += [row]*40\n",
    "aux_delta = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "aux_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banda theta\n",
    "df = pd.DataFrame(theta_bands)\n",
    "theta_df = df.transpose()\n",
    "theta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\n",
    "theta_df\n",
    "\n",
    "rows = list()\n",
    "for _,row in delta_df.iterrows():\n",
    "    rows += [row]*40\n",
    "aux_theta = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "aux_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bnada alpha\n",
    "df = pd.DataFrame(alpha_bands)\n",
    "alpha_df = df.transpose()\n",
    "alpha_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\n",
    "alpha_df\n",
    "\n",
    "rows = list()\n",
    "for _,row in delta_df.iterrows():\n",
    "    rows += [row]*40\n",
    "aux_alpha = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "aux_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banda beta\n",
    "df = pd.DataFrame(beta_bands)\n",
    "beta_df = df.transpose()\n",
    "beta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\n",
    "beta_df\n",
    "\n",
    "rows = list()\n",
    "for _,row in delta_df.iterrows():\n",
    "    rows += [row]*40\n",
    "aux_beta = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "aux_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banda gamma\n",
    "df = pd.DataFrame(gamma_bands)\n",
    "gamma_df = df.transpose()\n",
    "gamma_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\n",
    "gamma_df\n",
    "\n",
    "rows = list()\n",
    "for _,row in delta_df.iterrows():\n",
    "    rows += [row]*40\n",
    "aux_gamma = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "aux_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\n",
    "rows = list()\n",
    "for _,row in dfLabels.iterrows():\n",
    "    rows += [row]*64\n",
    "aux_labels = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "aux_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_delta = aux_delta.merge(aux_labels, left_index=True, right_index=True)\n",
    "data_theta = aux_theta.merge(aux_labels, left_index=True, right_index=True)\n",
    "data_alpha = aux_alpha.merge(aux_labels, left_index=True, right_index=True)\n",
    "data_beta = aux_beta.merge(aux_labels, left_index=True, right_index=True)\n",
    "data_gamma = aux_gamma.merge(aux_labels, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_delta.drop(['arousal', 'dominance', 'liking'], axis=1)\n",
    "    data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\n",
    "\n",
    "    data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    copia = data.copy()\n",
    "\n",
    "    y = copia[['valence']]\n",
    "\n",
    "    x = copia.drop(columns=['valence'])\n",
    "\n",
    "    # test_size = 0.2 --> 80% datos para entrenamiento, 20% para test\n",
    "    # max_depth --> The deeper the tree, the more splits it has and it captures more information about the data. En este modelo, valores altos de max_depths tienden a 'overfit' los datos, lo comprobamos en el siguiente bloque\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predict = clf.predict(xTest)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "    accuracy_score(yTest, predict)*100\n",
    "    \n",
    "    from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = svm.LinearSVC()\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\n",
    "svm_predict = svm_clf.predict(xTest)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 7\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "knn.fit(xTrain, np.ravel(yTrain))\n",
    "knn_predict = knn.predict(xTest)\n",
    "\n",
    "print(\"Banda delta Random Forest : \" + str(accuracy_score(yTest, predict)*100))\n",
    "print(\"Banda delta SVM : \" + str(accuracy_score(yTest, svm_predict)*100))\n",
    "print(\"Banda delta kNN : \" + str(accuracy_score(yTest, knn_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_theta.drop(['arousal', 'dominance', 'liking'], axis=1)\n",
    "    data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\n",
    "\n",
    "    data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    copia = data.copy()\n",
    "\n",
    "    y = copia[['valence']]\n",
    "\n",
    "    x = copia.drop(columns=['valence'])\n",
    "\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.1, random_state = 1)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predict = clf.predict(xTest)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = svm.LinearSVC()\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\n",
    "svm_predict = svm_clf.predict(xTest)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 7\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "knn.fit(xTrain, np.ravel(yTrain))\n",
    "knn_predict = knn.predict(xTest)\n",
    "\n",
    "print(\"Banda delta Random Forest : \" + str(accuracy_score(yTest, predict)*100))\n",
    "print(\"Banda delta SVM : \" + str(accuracy_score(yTest, svm_predict)*100))\n",
    "print(\"Banda delta kNN : \" + str(accuracy_score(yTest, knn_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = data_alpha.drop(['arousal', 'dominance', 'liking'], axis=1)\n",
    "    data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\n",
    "\n",
    "    data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    copia = data.copy()\n",
    "\n",
    "    y = copia[['valence']]\n",
    "\n",
    "    x = copia.drop(columns=['valence'])\n",
    "\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.15, random_state = 1)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predict = clf.predict(xTest)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    \n",
    "    from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = svm.LinearSVC()\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\n",
    "svm_predict = svm_clf.predict(xTest)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 7\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "knn.fit(xTrain, np.ravel(yTrain))\n",
    "knn_predict = knn.predict(xTest)\n",
    "\n",
    "print(\"Banda delta Random Forest : \" + str(accuracy_score(yTest, predict)*100))\n",
    "print(\"Banda delta SVM : \" + str(accuracy_score(yTest, svm_predict)*100))\n",
    "print(\"Banda delta kNN : \" + str(accuracy_score(yTest, knn_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   data = data_beta.drop(['arousal', 'dominance', 'liking'], axis=1)\n",
    "    data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\n",
    "\n",
    "    data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    copia = data.copy()\n",
    "\n",
    "    y = copia[['valence']]\n",
    "\n",
    "    x = copia.drop(columns=['valence'])\n",
    "\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predict = clf.predict(xTest)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    \n",
    "    from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = svm.LinearSVC()\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\n",
    "svm_predict = svm_clf.predict(xTest)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 7\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "knn.fit(xTrain, np.ravel(yTrain))\n",
    "knn_predict = knn.predict(xTest)\n",
    "\n",
    "print(\"Banda delta Random Forest : \" + str(accuracy_score(yTest, predict)*100))\n",
    "print(\"Banda delta SVM : \" + str(accuracy_score(yTest, svm_predict)*100))\n",
    "print(\"Banda delta kNN : \" + str(accuracy_score(yTest, knn_predict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = data_gamma.drop(['arousal', 'dominance', 'liking'], axis=1)\n",
    "    data['valence'] = np.where(data['valence'] >5, 'happy', 'sad')\n",
    "\n",
    "    data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','valence']\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    copia = data.copy()\n",
    "\n",
    "    y = copia[['valence']]\n",
    "\n",
    "    x = copia.drop(columns=['valence'])\n",
    "\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    predict = clf.predict(xTest)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    \n",
    "    from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = svm.LinearSVC()\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\n",
    "svm_predict = svm_clf.predict(xTest)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 7\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "knn.fit(xTrain, np.ravel(yTrain))\n",
    "knn_predict = knn.predict(xTest)\n",
    "\n",
    "print(\"Banda delta Random Forest : \" + str(accuracy_score(yTest, predict)*100))\n",
    "print(\"Banda delta SVM : \" + str(accuracy_score(yTest, svm_predict)*100))\n",
    "print(\"Banda delta kNN : \" + str(accuracy_score(yTest, knn_predict)*100))"
   ]
  }
 ]
}