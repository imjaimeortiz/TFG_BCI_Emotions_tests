{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1 subject. Feature extraction. Classification for each frequency band."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "from sklearn.multioutput import MultiOutputClassifier\r\n",
    "\r\n",
    "#def select_file(file):\r\n",
    "    #Lectura mediante pandas\r\n",
    "f = \"data_preprocessed_python\\\\s01.dat\"\r\n",
    "subject_id = 1\r\n",
    "\r\n",
    "dictRaw = pd.read_pickle(f)\r\n",
    "\r\n",
    "labels = dictRaw.get('labels')\r\n",
    "\r\n",
    "dfLabels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\r\n",
    "\r\n",
    "data = dictRaw.get('data')\r\n",
    "\r\n",
    "df_videos = {}\r\n",
    "    #Recorrido de cada una de las columnas de la tabla 3d, y guardado en una una lista de dataframes para cada uno de los videos.\r\n",
    "for i in range(40):\r\n",
    "    df_videos[i] = pd.DataFrame(data[i])\r\n",
    "    df_videos[i] = df_videos[i].transpose()\r\n",
    "    df_videos[i].columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature']\r\n",
    "    df_videos[i].drop(['hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature'],axis = 'columns', inplace=True)\r\n",
    "#df_videos"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "source": [
    "    # Frecuencia de muestreo\r\n",
    "    fs = 128\r\n",
    "    # Window\r\n",
    "    window = \"hann\"\r\n",
    "    # Length of each segment\r\n",
    "    # nperseg = 256 por defecto\r\n",
    "    # noverlap\r\n",
    "    # Por defecto a None, if None : noverlap = nperseg / 2\r\n",
    "    # [...]\r\n",
    "\r\n",
    "    # Definicion de bandas\r\n",
    "    eeg_bands = {'Delta': (1, 4),\r\n",
    "                'Theta': (4, 8),\r\n",
    "                'Alpha': (8, 14),\r\n",
    "                'Beta': (14, 30),\r\n",
    "                'Gamma': (30, 50)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "source": [
    "# FOURIER\r\n",
    "import scipy\r\n",
    "from scipy import signal\r\n",
    "\r\n",
    "# SE COGE EL PRIMER VÍDEOS, Df_VIDEOS[0]\r\n",
    "def do_stft(video, channel):\r\n",
    "    # Array \r\n",
    "    x = df_videos[video][channel]\r\n",
    "\r\n",
    "    # Array of the sample frequency, Array of the segment times, STFT of x\r\n",
    "    f, t , Zxx = scipy.signal.stft(x, fs, window)\r\n",
    "\r\n",
    "    #print(np.abs(Zxx))\r\n",
    "    '''\r\n",
    "    plt.pcolormesh(t, f, np.abs(Zxx), vmin=0, shading='gouraud')\r\n",
    "    plt.ylabel('Frequency [Hz]')\r\n",
    "    plt.xlabel('Time [sec]')\r\n",
    "    plt.show()\r\n",
    "    '''\r\n",
    "    return Zxx\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "source": [
    "#SEPARACION EN LAS DISTINTAS BANDAS DE FRECUENCIA\r\n",
    "\r\n",
    "def make_bands(Zxx):\r\n",
    "    #Obtener valores reales de STFT, solo positivos.\r\n",
    "    values = np.absolute(Zxx)\r\n",
    "\r\n",
    "    # Get frequencies for amplitudes in Hz\r\n",
    "    fft_freq = np.fft.rfftfreq(len(data), 1.0/fs)\r\n",
    "    #print(fft_freq)\r\n",
    "\r\n",
    "    # Obtención de cada una de las bandas de frecuencia\r\n",
    "    eeg_band_fft = dict()\r\n",
    "    for band in eeg_bands:  \r\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq <= eeg_bands[band][1]))[0]\r\n",
    "        eeg_band_fft[band] = values[freq_ix]\r\n",
    "\r\n",
    "    #print(eeg_band_fft)\r\n",
    "    '''\r\n",
    "    eeg_band_fft_means = dict()\r\n",
    "    for band in eeg_bands:  \r\n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & (fft_freq <= eeg_bands[band][1]))[0]\r\n",
    "        eeg_band_fft_means[band] = np.mean(values[freq_ix])\r\n",
    "\r\n",
    "    #print(eeg_band_fft_means)\r\n",
    "\r\n",
    "    #Graficación de las medias de los datos\r\n",
    "    df = pd.DataFrame(columns=['band', 'val'])\r\n",
    "    df['band'] = eeg_bands.keys()\r\n",
    "    df['val'] = [eeg_band_fft_means[band] for band in eeg_bands]\r\n",
    "    ax = df.plot.bar(x='band', y='val', legend=False)\r\n",
    "    ax.set_xlabel(\"EEG band\")\r\n",
    "    ax.set_ylabel(\"Mean band Amplitude\")\r\n",
    "    '''\r\n",
    "    #print(df)\r\n",
    "\r\n",
    "    #print(\"\\n\\n\")\r\n",
    "\r\n",
    "    '''\r\n",
    "    print(\"Shape de Zxx: \", Zxx.shape)\r\n",
    "    print(\"Shape de Delta: \", eeg_band_fft['Delta'].shape)\r\n",
    "    print(\"Shape de Theta: \", eeg_band_fft['Theta'].shape)\r\n",
    "    print(\"Shape de Alpha: \", eeg_band_fft['Alpha'].shape)\r\n",
    "    print(\"Shape de Beta: \", eeg_band_fft['Beta'].shape)\r\n",
    "    print(\"Shape de Gamma: \", eeg_band_fft['Gamma'].shape)\r\n",
    "    '''\r\n",
    "    return eeg_band_fft\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "source": [
    "# Ahora hay que hacer las medias sobre cada banda de frecuencia. La media entre cada una de las posiciones de los bloques. Hacer la media entre todas las posiciones 0, 1, 2... 63 de cada uno de los bloques\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "def channel_freq(eeg_band_fft):\r\n",
    "        \r\n",
    "        freq = np.zeros((5, 64))        # 5 bandas, 64 posiciones de los datos\r\n",
    "\r\n",
    "        # Se va a recorrer {Delta, Theta, Alpha, Beta, Gamma}\r\n",
    "        for band in eeg_bands:\r\n",
    "\r\n",
    "                # Para cada una de las 64 posiciones del array\r\n",
    "                for j in range (0, 64):\r\n",
    "                        \r\n",
    "                        val = []\r\n",
    "                        # Se va a recorrer cada uno de los arrays que hay en cada una de las bandas\r\n",
    "                        for i in range (0, len(eeg_band_fft[band])):\r\n",
    "                                val.append(eeg_band_fft[band][i][j])\r\n",
    "                                # Ejemplo : eeg_band_fft['Delta'][0][0*0 + 0]\r\n",
    "                        if (band == \"Delta\"):\r\n",
    "                                freq[0][j] = np.mean(val)\r\n",
    "                        elif (band == \"Theta\"):\r\n",
    "                                freq[1][j] = np.mean(val)\r\n",
    "                        elif (band == \"Alpha\"):\r\n",
    "                                freq[2][j] = np.mean(val)\r\n",
    "                        elif (band == \"Beta\"):\r\n",
    "                                freq[3][j] = np.mean(val)\r\n",
    "                        elif (band == \"Gamma\"):\r\n",
    "                                freq[4][j] = np.mean(val)\r\n",
    "        return(freq)     # En freq tenemos las frecuencias medias de cada una de las bandas\r\n",
    "\r\n",
    "# Recordamos : Estamos tratando los datos relativos al video 0, un canal concreto de un sujeto concreto"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "source": [
    "#df_file_videos = select_file('d\\\\s01.dat')\r\n",
    "# Obtener la división por bandas de frecuencia de cada uno de los canales del video 0\r\n",
    "for video in range(0, 40):\r\n",
    "    delta_bands = []\r\n",
    "    theta_bands = []\r\n",
    "    beta_bands = []\r\n",
    "    alpha_bands = []\r\n",
    "    gamma_bands = []\r\n",
    "\r\n",
    "    for channel in ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']:\r\n",
    "        Zxx = do_stft(video, channel)\r\n",
    "        eeg_band_fft = make_bands(Zxx)\r\n",
    "        freq = channel_freq(eeg_band_fft)\r\n",
    "\r\n",
    "        delta_bands.append(freq[0])\r\n",
    "        theta_bands.append(freq[1])\r\n",
    "        alpha_bands.append(freq[2])\r\n",
    "        beta_bands.append(freq[3])\r\n",
    "        gamma_bands.append(freq[4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "source": [
    "# Banda delta\r\n",
    "df = pd.DataFrame(delta_bands)\r\n",
    "delta_df = df.transpose()\r\n",
    "delta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "delta_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in delta_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_delta = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_delta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.023039  0.024048  0.028811  0.032106  0.044012  0.048092  0.016513   \n",
       "1     0.023039  0.024048  0.028811  0.032106  0.044012  0.048092  0.016513   \n",
       "2     0.023039  0.024048  0.028811  0.032106  0.044012  0.048092  0.016513   \n",
       "3     0.023039  0.024048  0.028811  0.032106  0.044012  0.048092  0.016513   \n",
       "4     0.023039  0.024048  0.028811  0.032106  0.044012  0.048092  0.016513   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.025769  0.026977  0.056836  0.010858  0.015764  0.051700  0.006908   \n",
       "2556  0.025769  0.026977  0.056836  0.010858  0.015764  0.051700  0.006908   \n",
       "2557  0.025769  0.026977  0.056836  0.010858  0.015764  0.051700  0.006908   \n",
       "2558  0.025769  0.026977  0.056836  0.010858  0.015764  0.051700  0.006908   \n",
       "2559  0.025769  0.026977  0.056836  0.010858  0.015764  0.051700  0.006908   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     0.050341  0.035829  0.011347  ...  0.072781  0.022990  0.019260   \n",
       "1     0.050341  0.035829  0.011347  ...  0.072781  0.022990  0.019260   \n",
       "2     0.050341  0.035829  0.011347  ...  0.072781  0.022990  0.019260   \n",
       "3     0.050341  0.035829  0.011347  ...  0.072781  0.022990  0.019260   \n",
       "4     0.050341  0.035829  0.011347  ...  0.072781  0.022990  0.019260   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  0.011550  0.038232  0.034416  ...  0.012704  0.008985  0.026565   \n",
       "2556  0.011550  0.038232  0.034416  ...  0.012704  0.008985  0.026565   \n",
       "2557  0.011550  0.038232  0.034416  ...  0.012704  0.008985  0.026565   \n",
       "2558  0.011550  0.038232  0.034416  ...  0.012704  0.008985  0.026565   \n",
       "2559  0.011550  0.038232  0.034416  ...  0.012704  0.008985  0.026565   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.010448  0.021503  0.038031  0.035371  0.003149  0.029362  0.033688  \n",
       "1     0.010448  0.021503  0.038031  0.035371  0.003149  0.029362  0.033688  \n",
       "2     0.010448  0.021503  0.038031  0.035371  0.003149  0.029362  0.033688  \n",
       "3     0.010448  0.021503  0.038031  0.035371  0.003149  0.029362  0.033688  \n",
       "4     0.010448  0.021503  0.038031  0.035371  0.003149  0.029362  0.033688  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.012750  0.029309  0.025757  0.056188  0.026164  0.045488  0.014212  \n",
       "2556  0.012750  0.029309  0.025757  0.056188  0.026164  0.045488  0.014212  \n",
       "2557  0.012750  0.029309  0.025757  0.056188  0.026164  0.045488  0.014212  \n",
       "2558  0.012750  0.029309  0.025757  0.056188  0.026164  0.045488  0.014212  \n",
       "2559  0.012750  0.029309  0.025757  0.056188  0.026164  0.045488  0.014212  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.028811</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072781</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.035371</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.033688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.028811</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072781</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.035371</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.033688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.028811</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072781</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.035371</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.033688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.028811</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072781</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.035371</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.033688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.028811</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.048092</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072781</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.021503</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.035371</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.033688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.025769</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.056836</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.038232</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.056188</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.014212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.025769</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.056836</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.038232</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.056188</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.014212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.025769</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.056836</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.038232</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.056188</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.014212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.025769</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.056836</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.038232</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.056188</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.014212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.025769</td>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.056836</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.038232</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.026565</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.056188</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.014212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 407
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "source": [
    "# Banda theta\r\n",
    "df = pd.DataFrame(theta_bands)\r\n",
    "theta_df = df.transpose()\r\n",
    "theta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "theta_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in theta_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_theta = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_theta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.017252  0.018866  0.023816  0.027844  0.050185  0.061815  0.016491   \n",
       "1     0.017252  0.018866  0.023816  0.027844  0.050185  0.061815  0.016491   \n",
       "2     0.017252  0.018866  0.023816  0.027844  0.050185  0.061815  0.016491   \n",
       "3     0.017252  0.018866  0.023816  0.027844  0.050185  0.061815  0.016491   \n",
       "4     0.017252  0.018866  0.023816  0.027844  0.050185  0.061815  0.016491   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.033588  0.035551  0.063285  0.008209  0.019997  0.064907  0.005452   \n",
       "2556  0.033588  0.035551  0.063285  0.008209  0.019997  0.064907  0.005452   \n",
       "2557  0.033588  0.035551  0.063285  0.008209  0.019997  0.064907  0.005452   \n",
       "2558  0.033588  0.035551  0.063285  0.008209  0.019997  0.064907  0.005452   \n",
       "2559  0.033588  0.035551  0.063285  0.008209  0.019997  0.064907  0.005452   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4       T8       FC6  \\\n",
       "0     0.057747  0.031317  0.007595  ...  0.075730  0.02869  0.020661   \n",
       "1     0.057747  0.031317  0.007595  ...  0.075730  0.02869  0.020661   \n",
       "2     0.057747  0.031317  0.007595  ...  0.075730  0.02869  0.020661   \n",
       "3     0.057747  0.031317  0.007595  ...  0.075730  0.02869  0.020661   \n",
       "4     0.057747  0.031317  0.007595  ...  0.075730  0.02869  0.020661   \n",
       "...        ...       ...       ...  ...       ...      ...       ...   \n",
       "2555  0.008309  0.041939  0.032092  ...  0.020028  0.01476  0.027922   \n",
       "2556  0.008309  0.041939  0.032092  ...  0.020028  0.01476  0.027922   \n",
       "2557  0.008309  0.041939  0.032092  ...  0.020028  0.01476  0.027922   \n",
       "2558  0.008309  0.041939  0.032092  ...  0.020028  0.01476  0.027922   \n",
       "2559  0.008309  0.041939  0.032092  ...  0.020028  0.01476  0.027922   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.013362  0.023908  0.042528  0.036502  0.002304  0.029287  0.032271  \n",
       "1     0.013362  0.023908  0.042528  0.036502  0.002304  0.029287  0.032271  \n",
       "2     0.013362  0.023908  0.042528  0.036502  0.002304  0.029287  0.032271  \n",
       "3     0.013362  0.023908  0.042528  0.036502  0.002304  0.029287  0.032271  \n",
       "4     0.013362  0.023908  0.042528  0.036502  0.002304  0.029287  0.032271  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.015252  0.031851  0.031492  0.059141  0.030113  0.048370  0.018528  \n",
       "2556  0.015252  0.031851  0.031492  0.059141  0.030113  0.048370  0.018528  \n",
       "2557  0.015252  0.031851  0.031492  0.059141  0.030113  0.048370  0.018528  \n",
       "2558  0.015252  0.031851  0.031492  0.059141  0.030113  0.048370  0.018528  \n",
       "2559  0.015252  0.031851  0.031492  0.059141  0.030113  0.048370  0.018528  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017252</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.027844</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.061815</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075730</td>\n",
       "      <td>0.02869</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017252</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.027844</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.061815</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075730</td>\n",
       "      <td>0.02869</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017252</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.027844</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.061815</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075730</td>\n",
       "      <td>0.02869</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017252</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.027844</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.061815</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075730</td>\n",
       "      <td>0.02869</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017252</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.027844</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.061815</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075730</td>\n",
       "      <td>0.02869</td>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>0.032271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.033588</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.019997</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.01476</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.059141</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.048370</td>\n",
       "      <td>0.018528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.033588</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.019997</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.01476</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.059141</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.048370</td>\n",
       "      <td>0.018528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.033588</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.019997</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.01476</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.059141</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.048370</td>\n",
       "      <td>0.018528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.033588</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.019997</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.01476</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.059141</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.048370</td>\n",
       "      <td>0.018528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.033588</td>\n",
       "      <td>0.035551</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.019997</td>\n",
       "      <td>0.064907</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.01476</td>\n",
       "      <td>0.027922</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.059141</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.048370</td>\n",
       "      <td>0.018528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 408
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "source": [
    "#Bnada alpha\r\n",
    "df = pd.DataFrame(alpha_bands)\r\n",
    "alpha_df = df.transpose()\r\n",
    "alpha_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "alpha_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in alpha_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_alpha = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_alpha"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.019937  0.022854  0.029019  0.034244  0.054900  0.069261  0.018295   \n",
       "1     0.019937  0.022854  0.029019  0.034244  0.054900  0.069261  0.018295   \n",
       "2     0.019937  0.022854  0.029019  0.034244  0.054900  0.069261  0.018295   \n",
       "3     0.019937  0.022854  0.029019  0.034244  0.054900  0.069261  0.018295   \n",
       "4     0.019937  0.022854  0.029019  0.034244  0.054900  0.069261  0.018295   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.033685  0.037036  0.067088  0.007560  0.024652  0.071946  0.006097   \n",
       "2556  0.033685  0.037036  0.067088  0.007560  0.024652  0.071946  0.006097   \n",
       "2557  0.033685  0.037036  0.067088  0.007560  0.024652  0.071946  0.006097   \n",
       "2558  0.033685  0.037036  0.067088  0.007560  0.024652  0.071946  0.006097   \n",
       "2559  0.033685  0.037036  0.067088  0.007560  0.024652  0.071946  0.006097   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     0.062502  0.032166  0.008225  ...  0.082650  0.034306  0.027026   \n",
       "1     0.062502  0.032166  0.008225  ...  0.082650  0.034306  0.027026   \n",
       "2     0.062502  0.032166  0.008225  ...  0.082650  0.034306  0.027026   \n",
       "3     0.062502  0.032166  0.008225  ...  0.082650  0.034306  0.027026   \n",
       "4     0.062502  0.032166  0.008225  ...  0.082650  0.034306  0.027026   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  0.009998  0.041666  0.039836  ...  0.035355  0.023049  0.034356   \n",
       "2556  0.009998  0.041666  0.039836  ...  0.035355  0.023049  0.034356   \n",
       "2557  0.009998  0.041666  0.039836  ...  0.035355  0.023049  0.034356   \n",
       "2558  0.009998  0.041666  0.039836  ...  0.035355  0.023049  0.034356   \n",
       "2559  0.009998  0.041666  0.039836  ...  0.035355  0.023049  0.034356   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.019712  0.026368  0.046145  0.041746  0.008357  0.032070  0.039993  \n",
       "1     0.019712  0.026368  0.046145  0.041746  0.008357  0.032070  0.039993  \n",
       "2     0.019712  0.026368  0.046145  0.041746  0.008357  0.032070  0.039993  \n",
       "3     0.019712  0.026368  0.046145  0.041746  0.008357  0.032070  0.039993  \n",
       "4     0.019712  0.026368  0.046145  0.041746  0.008357  0.032070  0.039993  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.023025  0.036246  0.036683  0.066209  0.039338  0.054329  0.023807  \n",
       "2556  0.023025  0.036246  0.036683  0.066209  0.039338  0.054329  0.023807  \n",
       "2557  0.023025  0.036246  0.036683  0.066209  0.039338  0.054329  0.023807  \n",
       "2558  0.023025  0.036246  0.036683  0.066209  0.039338  0.054329  0.023807  \n",
       "2559  0.023025  0.036246  0.036683  0.066209  0.039338  0.054329  0.023807  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.034244</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.019712</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>0.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.034244</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.019712</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>0.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.034244</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.019712</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>0.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.034244</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.019712</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>0.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.034244</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.062502</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>0.034306</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.019712</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>0.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.067088</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.071946</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>0.039338</td>\n",
       "      <td>0.054329</td>\n",
       "      <td>0.023807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.067088</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.071946</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>0.039338</td>\n",
       "      <td>0.054329</td>\n",
       "      <td>0.023807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.067088</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.071946</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>0.039338</td>\n",
       "      <td>0.054329</td>\n",
       "      <td>0.023807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.067088</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.071946</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>0.039338</td>\n",
       "      <td>0.054329</td>\n",
       "      <td>0.023807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.067088</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.071946</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>0.039338</td>\n",
       "      <td>0.054329</td>\n",
       "      <td>0.023807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 409
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "source": [
    "# Banda beta\r\n",
    "df = pd.DataFrame(beta_bands)\r\n",
    "beta_df = df.transpose()\r\n",
    "beta_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "beta_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in beta_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_beta = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_beta"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.074772  0.122948  0.120034  0.094305  0.123077  0.200693  0.060057   \n",
       "1     0.074772  0.122948  0.120034  0.094305  0.123077  0.200693  0.060057   \n",
       "2     0.074772  0.122948  0.120034  0.094305  0.123077  0.200693  0.060057   \n",
       "3     0.074772  0.122948  0.120034  0.094305  0.123077  0.200693  0.060057   \n",
       "4     0.074772  0.122948  0.120034  0.094305  0.123077  0.200693  0.060057   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.040818  0.105418  0.185211  0.107109  0.100188  0.242917  0.101689   \n",
       "2556  0.040818  0.105418  0.185211  0.107109  0.100188  0.242917  0.101689   \n",
       "2557  0.040818  0.105418  0.185211  0.107109  0.100188  0.242917  0.101689   \n",
       "2558  0.040818  0.105418  0.185211  0.107109  0.100188  0.242917  0.101689   \n",
       "2559  0.040818  0.105418  0.185211  0.107109  0.100188  0.242917  0.101689   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     0.098501  0.065002  0.030612  ...  0.162639  0.106128  0.110137   \n",
       "1     0.098501  0.065002  0.030612  ...  0.162639  0.106128  0.110137   \n",
       "2     0.098501  0.065002  0.030612  ...  0.162639  0.106128  0.110137   \n",
       "3     0.098501  0.065002  0.030612  ...  0.162639  0.106128  0.110137   \n",
       "4     0.098501  0.065002  0.030612  ...  0.162639  0.106128  0.110137   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  0.052823  0.069783  0.167223  ...  0.183980  0.171910  0.176778   \n",
       "2556  0.052823  0.069783  0.167223  ...  0.183980  0.171910  0.176778   \n",
       "2557  0.052823  0.069783  0.167223  ...  0.183980  0.171910  0.176778   \n",
       "2558  0.052823  0.069783  0.167223  ...  0.183980  0.171910  0.176778   \n",
       "2559  0.052823  0.069783  0.167223  ...  0.183980  0.171910  0.176778   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.068395  0.060210  0.102504  0.091276  0.113631  0.096028  0.073698  \n",
       "1     0.068395  0.060210  0.102504  0.091276  0.113631  0.096028  0.073698  \n",
       "2     0.068395  0.060210  0.102504  0.091276  0.113631  0.096028  0.073698  \n",
       "3     0.068395  0.060210  0.102504  0.091276  0.113631  0.096028  0.073698  \n",
       "4     0.068395  0.060210  0.102504  0.091276  0.113631  0.096028  0.073698  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.226287  0.159771  0.090470  0.156451  0.214108  0.127266  0.111628  \n",
       "2556  0.226287  0.159771  0.090470  0.156451  0.214108  0.127266  0.111628  \n",
       "2557  0.226287  0.159771  0.090470  0.156451  0.214108  0.127266  0.111628  \n",
       "2558  0.226287  0.159771  0.090470  0.156451  0.214108  0.127266  0.111628  \n",
       "2559  0.226287  0.159771  0.090470  0.156451  0.214108  0.127266  0.111628  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074772</td>\n",
       "      <td>0.122948</td>\n",
       "      <td>0.120034</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>0.098501</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162639</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>0.068395</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.102504</td>\n",
       "      <td>0.091276</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.096028</td>\n",
       "      <td>0.073698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074772</td>\n",
       "      <td>0.122948</td>\n",
       "      <td>0.120034</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>0.098501</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162639</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>0.068395</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.102504</td>\n",
       "      <td>0.091276</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.096028</td>\n",
       "      <td>0.073698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074772</td>\n",
       "      <td>0.122948</td>\n",
       "      <td>0.120034</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>0.098501</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162639</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>0.068395</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.102504</td>\n",
       "      <td>0.091276</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.096028</td>\n",
       "      <td>0.073698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.074772</td>\n",
       "      <td>0.122948</td>\n",
       "      <td>0.120034</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>0.098501</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162639</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>0.068395</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.102504</td>\n",
       "      <td>0.091276</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.096028</td>\n",
       "      <td>0.073698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074772</td>\n",
       "      <td>0.122948</td>\n",
       "      <td>0.120034</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>0.098501</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162639</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>0.068395</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.102504</td>\n",
       "      <td>0.091276</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.096028</td>\n",
       "      <td>0.073698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.040818</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.185211</td>\n",
       "      <td>0.107109</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.242917</td>\n",
       "      <td>0.101689</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.167223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183980</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>0.226287</td>\n",
       "      <td>0.159771</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.156451</td>\n",
       "      <td>0.214108</td>\n",
       "      <td>0.127266</td>\n",
       "      <td>0.111628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.040818</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.185211</td>\n",
       "      <td>0.107109</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.242917</td>\n",
       "      <td>0.101689</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.167223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183980</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>0.226287</td>\n",
       "      <td>0.159771</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.156451</td>\n",
       "      <td>0.214108</td>\n",
       "      <td>0.127266</td>\n",
       "      <td>0.111628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.040818</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.185211</td>\n",
       "      <td>0.107109</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.242917</td>\n",
       "      <td>0.101689</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.167223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183980</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>0.226287</td>\n",
       "      <td>0.159771</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.156451</td>\n",
       "      <td>0.214108</td>\n",
       "      <td>0.127266</td>\n",
       "      <td>0.111628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.040818</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.185211</td>\n",
       "      <td>0.107109</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.242917</td>\n",
       "      <td>0.101689</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.167223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183980</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>0.226287</td>\n",
       "      <td>0.159771</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.156451</td>\n",
       "      <td>0.214108</td>\n",
       "      <td>0.127266</td>\n",
       "      <td>0.111628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.040818</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.185211</td>\n",
       "      <td>0.107109</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.242917</td>\n",
       "      <td>0.101689</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.167223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183980</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>0.226287</td>\n",
       "      <td>0.159771</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.156451</td>\n",
       "      <td>0.214108</td>\n",
       "      <td>0.127266</td>\n",
       "      <td>0.111628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 410
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "source": [
    "# Banda gamma\r\n",
    "df = pd.DataFrame(gamma_bands)\r\n",
    "gamma_df = df.transpose()\r\n",
    "gamma_df.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']\r\n",
    "gamma_df\r\n",
    "\r\n",
    "rows = list()\r\n",
    "for _,row in gamma_df.iterrows():\r\n",
    "    rows += [row]*40\r\n",
    "aux_gamma = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_gamma"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           FP1       AF3        F7        F3       FC1       FC5        T7  \\\n",
       "0     0.234008  0.333754  0.327015  0.347129  0.342250  0.403499  0.239339   \n",
       "1     0.234008  0.333754  0.327015  0.347129  0.342250  0.403499  0.239339   \n",
       "2     0.234008  0.333754  0.327015  0.347129  0.342250  0.403499  0.239339   \n",
       "3     0.234008  0.333754  0.327015  0.347129  0.342250  0.403499  0.239339   \n",
       "4     0.234008  0.333754  0.327015  0.347129  0.342250  0.403499  0.239339   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2555  0.059516  0.157184  0.216002  0.247524  0.108213  0.300691  0.210246   \n",
       "2556  0.059516  0.157184  0.216002  0.247524  0.108213  0.300691  0.210246   \n",
       "2557  0.059516  0.157184  0.216002  0.247524  0.108213  0.300691  0.210246   \n",
       "2558  0.059516  0.157184  0.216002  0.247524  0.108213  0.300691  0.210246   \n",
       "2559  0.059516  0.157184  0.216002  0.247524  0.108213  0.300691  0.210246   \n",
       "\n",
       "            C3       CP1       CP5  ...        C4        T8       FC6  \\\n",
       "0     0.170319  0.185646  0.147057  ...  0.596176  0.299382  0.389189   \n",
       "1     0.170319  0.185646  0.147057  ...  0.596176  0.299382  0.389189   \n",
       "2     0.170319  0.185646  0.147057  ...  0.596176  0.299382  0.389189   \n",
       "3     0.170319  0.185646  0.147057  ...  0.596176  0.299382  0.389189   \n",
       "4     0.170319  0.185646  0.147057  ...  0.596176  0.299382  0.389189   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2555  0.229857  0.294505  0.185836  ...  0.254134  0.208087  0.180113   \n",
       "2556  0.229857  0.294505  0.185836  ...  0.254134  0.208087  0.180113   \n",
       "2557  0.229857  0.294505  0.185836  ...  0.254134  0.208087  0.180113   \n",
       "2558  0.229857  0.294505  0.185836  ...  0.254134  0.208087  0.180113   \n",
       "2559  0.229857  0.294505  0.185836  ...  0.254134  0.208087  0.180113   \n",
       "\n",
       "           FC2        F4        F8       AF4       Fp2        Fz        Cz  \n",
       "0     0.198125  0.254384  0.197694  0.217398  0.300440  0.373761  0.425536  \n",
       "1     0.198125  0.254384  0.197694  0.217398  0.300440  0.373761  0.425536  \n",
       "2     0.198125  0.254384  0.197694  0.217398  0.300440  0.373761  0.425536  \n",
       "3     0.198125  0.254384  0.197694  0.217398  0.300440  0.373761  0.425536  \n",
       "4     0.198125  0.254384  0.197694  0.217398  0.300440  0.373761  0.425536  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2555  0.467545  0.298015  0.161810  0.274674  0.369125  0.256507  0.241600  \n",
       "2556  0.467545  0.298015  0.161810  0.274674  0.369125  0.256507  0.241600  \n",
       "2557  0.467545  0.298015  0.161810  0.274674  0.369125  0.256507  0.241600  \n",
       "2558  0.467545  0.298015  0.161810  0.274674  0.369125  0.256507  0.241600  \n",
       "2559  0.467545  0.298015  0.161810  0.274674  0.369125  0.256507  0.241600  \n",
       "\n",
       "[2560 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>C3</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP5</th>\n",
       "      <th>...</th>\n",
       "      <th>C4</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>FC2</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234008</td>\n",
       "      <td>0.333754</td>\n",
       "      <td>0.327015</td>\n",
       "      <td>0.347129</td>\n",
       "      <td>0.342250</td>\n",
       "      <td>0.403499</td>\n",
       "      <td>0.239339</td>\n",
       "      <td>0.170319</td>\n",
       "      <td>0.185646</td>\n",
       "      <td>0.147057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596176</td>\n",
       "      <td>0.299382</td>\n",
       "      <td>0.389189</td>\n",
       "      <td>0.198125</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>0.197694</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.300440</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.234008</td>\n",
       "      <td>0.333754</td>\n",
       "      <td>0.327015</td>\n",
       "      <td>0.347129</td>\n",
       "      <td>0.342250</td>\n",
       "      <td>0.403499</td>\n",
       "      <td>0.239339</td>\n",
       "      <td>0.170319</td>\n",
       "      <td>0.185646</td>\n",
       "      <td>0.147057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596176</td>\n",
       "      <td>0.299382</td>\n",
       "      <td>0.389189</td>\n",
       "      <td>0.198125</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>0.197694</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.300440</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.234008</td>\n",
       "      <td>0.333754</td>\n",
       "      <td>0.327015</td>\n",
       "      <td>0.347129</td>\n",
       "      <td>0.342250</td>\n",
       "      <td>0.403499</td>\n",
       "      <td>0.239339</td>\n",
       "      <td>0.170319</td>\n",
       "      <td>0.185646</td>\n",
       "      <td>0.147057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596176</td>\n",
       "      <td>0.299382</td>\n",
       "      <td>0.389189</td>\n",
       "      <td>0.198125</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>0.197694</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.300440</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.234008</td>\n",
       "      <td>0.333754</td>\n",
       "      <td>0.327015</td>\n",
       "      <td>0.347129</td>\n",
       "      <td>0.342250</td>\n",
       "      <td>0.403499</td>\n",
       "      <td>0.239339</td>\n",
       "      <td>0.170319</td>\n",
       "      <td>0.185646</td>\n",
       "      <td>0.147057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596176</td>\n",
       "      <td>0.299382</td>\n",
       "      <td>0.389189</td>\n",
       "      <td>0.198125</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>0.197694</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.300440</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234008</td>\n",
       "      <td>0.333754</td>\n",
       "      <td>0.327015</td>\n",
       "      <td>0.347129</td>\n",
       "      <td>0.342250</td>\n",
       "      <td>0.403499</td>\n",
       "      <td>0.239339</td>\n",
       "      <td>0.170319</td>\n",
       "      <td>0.185646</td>\n",
       "      <td>0.147057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596176</td>\n",
       "      <td>0.299382</td>\n",
       "      <td>0.389189</td>\n",
       "      <td>0.198125</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>0.197694</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.300440</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.425536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.157184</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>0.247524</td>\n",
       "      <td>0.108213</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.210246</td>\n",
       "      <td>0.229857</td>\n",
       "      <td>0.294505</td>\n",
       "      <td>0.185836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254134</td>\n",
       "      <td>0.208087</td>\n",
       "      <td>0.180113</td>\n",
       "      <td>0.467545</td>\n",
       "      <td>0.298015</td>\n",
       "      <td>0.161810</td>\n",
       "      <td>0.274674</td>\n",
       "      <td>0.369125</td>\n",
       "      <td>0.256507</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.157184</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>0.247524</td>\n",
       "      <td>0.108213</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.210246</td>\n",
       "      <td>0.229857</td>\n",
       "      <td>0.294505</td>\n",
       "      <td>0.185836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254134</td>\n",
       "      <td>0.208087</td>\n",
       "      <td>0.180113</td>\n",
       "      <td>0.467545</td>\n",
       "      <td>0.298015</td>\n",
       "      <td>0.161810</td>\n",
       "      <td>0.274674</td>\n",
       "      <td>0.369125</td>\n",
       "      <td>0.256507</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.157184</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>0.247524</td>\n",
       "      <td>0.108213</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.210246</td>\n",
       "      <td>0.229857</td>\n",
       "      <td>0.294505</td>\n",
       "      <td>0.185836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254134</td>\n",
       "      <td>0.208087</td>\n",
       "      <td>0.180113</td>\n",
       "      <td>0.467545</td>\n",
       "      <td>0.298015</td>\n",
       "      <td>0.161810</td>\n",
       "      <td>0.274674</td>\n",
       "      <td>0.369125</td>\n",
       "      <td>0.256507</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.157184</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>0.247524</td>\n",
       "      <td>0.108213</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.210246</td>\n",
       "      <td>0.229857</td>\n",
       "      <td>0.294505</td>\n",
       "      <td>0.185836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254134</td>\n",
       "      <td>0.208087</td>\n",
       "      <td>0.180113</td>\n",
       "      <td>0.467545</td>\n",
       "      <td>0.298015</td>\n",
       "      <td>0.161810</td>\n",
       "      <td>0.274674</td>\n",
       "      <td>0.369125</td>\n",
       "      <td>0.256507</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.157184</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>0.247524</td>\n",
       "      <td>0.108213</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.210246</td>\n",
       "      <td>0.229857</td>\n",
       "      <td>0.294505</td>\n",
       "      <td>0.185836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254134</td>\n",
       "      <td>0.208087</td>\n",
       "      <td>0.180113</td>\n",
       "      <td>0.467545</td>\n",
       "      <td>0.298015</td>\n",
       "      <td>0.161810</td>\n",
       "      <td>0.274674</td>\n",
       "      <td>0.369125</td>\n",
       "      <td>0.256507</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 411
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "source": [
    "df_labels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\r\n",
    "rows = list()\r\n",
    "for _,row in dfLabels.iterrows():\r\n",
    "    rows += [row]*64\r\n",
    "aux_labels = pd.DataFrame(rows).reset_index(drop=True)\r\n",
    "\r\n",
    "aux_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      valence  arousal  dominance  liking\n",
       "0        7.71     7.60       6.90    7.83\n",
       "1        7.71     7.60       6.90    7.83\n",
       "2        7.71     7.60       6.90    7.83\n",
       "3        7.71     7.60       6.90    7.83\n",
       "4        7.71     7.60       6.90    7.83\n",
       "...       ...      ...        ...     ...\n",
       "2555     5.10     7.12       6.17    5.97\n",
       "2556     5.10     7.12       6.17    5.97\n",
       "2557     5.10     7.12       6.17    5.97\n",
       "2558     5.10     7.12       6.17    5.97\n",
       "2559     5.10     7.12       6.17    5.97\n",
       "\n",
       "[2560 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>liking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.71</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>5.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>6.17</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>5.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>6.17</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>5.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>6.17</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>5.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>6.17</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>5.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>6.17</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 412
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "source": [
    "data_delta = aux_delta.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_theta = aux_theta.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_alpha = aux_alpha.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_beta = aux_beta.merge(aux_labels, left_index=True, right_index=True)\r\n",
    "data_gamma = aux_gamma.merge(aux_labels, left_index=True, right_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "source": [
    "data = data_delta.drop(['dominance', 'liking'], axis=1)\r\n",
    "\r\n",
    "conditions = [\r\n",
    "    ((data['valence'] <4.5) & (data['arousal']<4.5)),\r\n",
    "    ((data['valence'] <4.5) & (data['arousal'] > 4.5)),\r\n",
    "    ((data['valence'] >4.5) & (data['arousal']<4.5)),\r\n",
    "    ((data['valence'] >4.5) & (data['arousal'] > 4.5))]\r\n",
    "choices = ['sadness', 'pleasure', 'anger', 'joy']\r\n",
    "'''\r\n",
    "label = np.where((data['valence'] <4.5) & (data['arousal']<4.5), 'sadness')\r\n",
    "label = np.where((data['valence'] <4.5) & (data['arousal'] > 4.5), 'pleasure')\r\n",
    "label = np.where((data['valence'] >4.5) & (data['arousal']<4.5), 'anger')\r\n",
    "label = np.where((data['valence'] >4.5) & (data['arousal'] > 4.5), 'joy')\r\n",
    "'''\r\n",
    "data['valence'] = np.select(conditions, choices, default='black')\r\n",
    "data = data.drop(columns='arousal')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz', 'label']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia['label']\r\n",
    "\r\n",
    "x = copia.drop(columns=['label'])\r\n",
    "\r\n",
    "    # test_size = 0.2 --> 80% datos para entrenamiento, 20% para test\r\n",
    "    # max_depth --> The deeper the tree, the more splits it has and it captures more information about the data. En este modelo, valores altos de max_depths tienden a 'overfit' los datos, lo comprobamos en el siguiente bloque\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "\r\n",
    "accuracy_score(yTest, predict)*100\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "svm_clf = svm.SVC(kernel='poly', degree=15, C=100, decision_function_shape='ovo')\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_delta = accuracy_score(yTest, predict)\r\n",
    "svm_acc_delta = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_delta = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "print(classification_report(yTest, predict, target_names=[\"sadness\", \"pleasure\", \"anger\", \"joy\"]))\r\n",
    "print(classification_report(yTest, svm_predict, target_names=[\"sadness\", \"pleasure\", \"anger\", \"joy\"]))\r\n",
    "print(classification_report(yTest, knn_predict, target_names=[\"sadness\", \"pleasure\", \"anger\", \"joy\"]))\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "print(precision_score(yTest, predict, average=\"micro\", labels=[\"joy\"]))\r\n",
    "\r\n",
    "\r\n",
    "rf_prec_sadness_delta = precision_score(yTest, predict)\r\n",
    "rf_prec_pleasure_delta = precision_score(yTest, predict)\r\n",
    "rf_prec_anger_delta = precision_score(yTest, predict)\r\n",
    "rf_prec_joy_delta = precision_score(yTest, predict)\r\n",
    "\r\n",
    "svm_prec_sadness_delta = precision_score(yTest, svm_predict)\r\n",
    "svm_prec_pleasure_delta = precision_score(yTest, svm_predict)\r\n",
    "svm_prec_anger_delta = precision_score(yTest, svm_predict)\r\n",
    "svm_prec_joy_delta = precision_score(yTest, svm_predict)\r\n",
    "\r\n",
    "knn_prec_sadness_delta = precision_score(yTest, knn_predict)\r\n",
    "knn_prec_pleasure_delta = precision_score(yTest, knn_predict)\r\n",
    "knn_prec_anger_delta = precision_score(yTest, knn_predict)\r\n",
    "knn_prec_joy_delta = precision_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "print(recall_score(yTest, predict, average=\"micro\", labels=[\"joy\"]))\r\n",
    "\r\n",
    "rf_rec_sadness_delta = recall_score(yTest, predict)\r\n",
    "rf_rec_pleasure_delta = recall_score(yTest, predict)\r\n",
    "rf_rec_anger_delta = recall_score(yTest, predict)\r\n",
    "rf_rec_joy_delta = recall_score(yTest, predict)\r\n",
    "\r\n",
    "svm_rec_sadness_delta = recall_score(yTest, svm_predict)\r\n",
    "svm_rec_pleasure_delta = recall_score(yTest, svm_predict)\r\n",
    "svm_rec_anger_delta = recall_score(yTest, svm_predict)\r\n",
    "svm_rec_joy_delta = recall_score(yTest, svm_predict)\r\n",
    "\r\n",
    "knn_rec_sadness_delta = recall_score(yTest, knn_predict)\r\n",
    "knn_rec_pleasure_delta = recall_score(yTest, knn_predict)\r\n",
    "knn_rec_anger_delta = recall_score(yTest, knn_predict)\r\n",
    "knn_rec_joy_delta = recall_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "print(f1_score(yTest, predict, average=\"micro\", labels=[\"joy\"]))\r\n",
    "\r\n",
    "rf_f1_sadness_delta = f1_score(yTest, predict)\r\n",
    "rf_f1_pleasure_delta = f1_score(yTest, predict)\r\n",
    "rf_f1_anger_delta = f1_score(yTest, predict)\r\n",
    "rf_f1_joy_delta = f1_score(yTest, predict)\r\n",
    "\r\n",
    "svm_f1_sadness_delta = f1_score(yTest, svm_predict)\r\n",
    "svm_f1_joy_delta = f1_score(yTest, svm_predict)\r\n",
    "svm_f1_anger_delta = f1_score(yTest, svm_predict)\r\n",
    "svm_f1_joy_delta = f1_score(yTest, svm_predict)\r\n",
    "\r\n",
    "knn_f1_sadness_delta = f1_score(yTest, knn_predict)\r\n",
    "knn_f1_pleasure_delta = f1_score(yTest, knn_predict)\r\n",
    "knn_f1_anger_delta = f1_score(yTest, knn_predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.00      0.00      0.00        72\n",
      "    pleasure       0.71      0.81      0.76       181\n",
      "       anger       0.48      0.95      0.64       144\n",
      "         joy       0.86      0.16      0.26       115\n",
      "\n",
      "    accuracy                           0.59       512\n",
      "   macro avg       0.51      0.48      0.42       512\n",
      "weighted avg       0.58      0.59      0.51       512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.81      0.94      0.87        72\n",
      "    pleasure       0.93      0.92      0.92       181\n",
      "       anger       0.95      0.91      0.93       144\n",
      "         joy       0.95      0.92      0.93       115\n",
      "\n",
      "    accuracy                           0.92       512\n",
      "   macro avg       0.91      0.92      0.91       512\n",
      "weighted avg       0.92      0.92      0.92       512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.92      0.94      0.93        72\n",
      "    pleasure       0.97      0.92      0.94       181\n",
      "       anger       0.90      0.90      0.90       144\n",
      "         joy       0.89      0.95      0.92       115\n",
      "\n",
      "    accuracy                           0.92       512\n",
      "   macro avg       0.92      0.93      0.92       512\n",
      "weighted avg       0.92      0.92      0.92       512\n",
      "\n",
      "0.7135922330097088\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-414-321b02e9c040>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mrf_prec_sadness_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[0mrf_prec_pleasure_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mrf_prec_anger_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1655\u001b[0m     \"\"\"\n\u001b[1;32m-> 1656\u001b[1;33m     p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1657\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1465\u001b[0m                                     pos_label)\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1294\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1295\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(accuracy_score(yTest, predict, labels=[\"joy\"]))\r\n",
    "svm_acc_delta = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_delta = accuracy_score(yTest, knn_predict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(rf_prec_sadness_delta)\r\n",
    "print(rf_prec_pleasure_delta)\r\n",
    "print(rf_prec_anger_delta)\r\n",
    "print(rf_prec_joy_delta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_theta.drop(['dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.select(conditions, choices, default='black')\r\n",
    "data = data.drop(columns='arousal')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz', 'label']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia['label']\r\n",
    "\r\n",
    "x = copia.drop(columns=['label'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "svm_clf = svm.LinearSVC()\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_theta = accuracy_score(yTest, predict)\r\n",
    "svm_acc_theta = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_theta = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_theta = precision_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_prec_sad_theta = precision_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_prec_happy_theta = precision_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_prec_sad_theta = precision_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_prec_happy_theta = precision_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_prec_sad_theta = precision_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_prec_happy_theta = precision_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_prec_sad_theta = precision_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_prec_happy_theta = precision_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_prec_sad_theta = precision_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_prec_happy_theta = precision_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_prec_sad_theta = precision_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_theta = recall_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_rec_sad_theta = recall_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_rec_happy_theta = recall_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_rec_sad_theta = recall_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_rec_happy_theta = recall_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_rec_sad_theta = recall_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_rec_happy_theta = recall_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_rec_sad_theta = recall_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_rec_happy_theta = recall_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_rec_sad_theta = recall_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_rec_happy_theta = recall_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_rec_sad_theta = recall_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_theta = f1_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_f1_sad_theta = f1_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_f1_happy_theta = f1_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_f1_sad_theta = f1_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_f1_happy_theta = f1_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_f1_sad_theta = f1_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_f1_happy_theta = f1_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_f1_sad_theta = f1_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_f1_happy_theta = f1_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_f1_sad_theta = f1_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_f1_happy_theta = f1_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_f1_sad_theta = f1_score(yTest, knn_predict, pos_label=\"joy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_alpha.drop(['dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.select(conditions, choices, default='black')\r\n",
    "data = data.drop(columns='arousal')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz', 'label']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia['label']\r\n",
    "\r\n",
    "x = copia.drop(columns=['label'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "svm_clf = svm.LinearSVC()\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_alpha = accuracy_score(yTest, predict)\r\n",
    "svm_acc_alpha = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_alpha = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_alpha = precision_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_prec_sad_alpha = precision_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_prec_happy_alpha = precision_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_prec_sad_alpha = precision_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_prec_happy_alpha = precision_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_prec_sad_alpha = precision_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_prec_happy_alpha = precision_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_prec_sad_alpha = precision_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_prec_happy_alpha = precision_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_prec_sad_alpha = precision_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_prec_happy_alpha = precision_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_prec_sad_alpha = precision_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_alpha = recall_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_rec_sad_alpha = recall_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_rec_happy_alpha = recall_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_rec_sad_alpha = recall_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_rec_happy_alpha = recall_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_rec_sad_alpha = recall_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_rec_happy_alpha = recall_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_rec_sad_alpha = recall_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_rec_happy_alpha = recall_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_rec_sad_alpha = recall_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_rec_happy_alpha = recall_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_rec_sad_alpha = recall_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_alpha = f1_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_f1_sad_alpha = f1_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_f1_happy_alpha = f1_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_f1_sad_alpha = f1_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_f1_happy_alpha = f1_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_f1_sad_alpha = f1_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_f1_happy_alpha = f1_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_f1_sad_alpha = f1_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_f1_happy_alpha = f1_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_f1_sad_alpha = f1_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_f1_happy_alpha = f1_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_f1_sad_alpha = f1_score(yTest, knn_predict, pos_label=\"joy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_beta.drop(['dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.select(conditions, choices, default='black')\r\n",
    "data = data.drop(columns='arousal')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz', 'label']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia['label']\r\n",
    "\r\n",
    "x = copia.drop(columns=['label'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "svm_clf = svm.LinearSVC()\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_beta = accuracy_score(yTest, predict)\r\n",
    "svm_acc_beta = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_beta = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_beta = precision_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_prec_sad_beta = precision_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_prec_happy_beta = precision_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_prec_sad_beta = precision_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_prec_happy_beta = precision_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_prec_sad_beta = precision_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_prec_happy_beta = precision_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_prec_sad_beta = precision_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_prec_happy_beta = precision_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_prec_sad_beta = precision_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_prec_happy_beta = precision_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_prec_sad_beta = precision_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_beta = recall_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_rec_sad_beta = recall_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_rec_happy_beta = recall_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_rec_sad_beta = recall_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_rec_happy_beta = recall_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_rec_sad_beta = recall_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_rec_happy_beta = recall_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_rec_sad_beta = recall_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_rec_happy_beta = recall_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_rec_sad_beta = recall_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_rec_happy_beta = recall_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_rec_sad_beta = recall_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_beta = f1_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_f1_sad_beta = f1_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_f1_happy_beta = f1_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_f1_sad_beta = f1_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_f1_happy_beta = f1_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_f1_sad_beta = f1_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_f1_happy_beta = f1_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_f1_sad_beta = f1_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_f1_happy_beta = f1_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_f1_sad_beta = f1_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_f1_happy_beta = f1_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_f1_sad_beta = f1_score(yTest, knn_predict, pos_label=\"joy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data_gamma.drop(['dominance', 'liking'], axis=1)\r\n",
    "data['valence'] = np.select(conditions, choices, default='black')\r\n",
    "data = data.drop(columns='arousal')\r\n",
    "\r\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz', 'label']\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "copia = data.copy()\r\n",
    "\r\n",
    "y = copia['label']\r\n",
    "\r\n",
    "x = copia.drop(columns=['label'])\r\n",
    "\r\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\r\n",
    "clf.fit(xTrain, yTrain)\r\n",
    "\r\n",
    "predict = clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "    \r\n",
    "from sklearn import svm\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "svm_clf = svm.LinearSVC()\r\n",
    "svm_clf.fit(xTrain, np.ravel(yTrain))\r\n",
    "svm_predict = svm_clf.predict(xTest)\r\n",
    "\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "n_neighbors = 7\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors)\r\n",
    "knn.fit(xTrain, np.ravel(yTrain))\r\n",
    "knn_predict = knn.predict(xTest)\r\n",
    "\r\n",
    "rf_acc_gamma = accuracy_score(yTest, predict)\r\n",
    "svm_acc_gamma = accuracy_score(yTest, svm_predict)\r\n",
    "knn_acc_gamma = accuracy_score(yTest, knn_predict)\r\n",
    "\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "rf_prec_happy_gamma = precision_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_prec_sad_gamma = precision_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_prec_happy_gamma = precision_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_prec_sad_gamma = precision_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_prec_happy_gamma = precision_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_prec_sad_gamma = precision_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_prec_happy_gamma = precision_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_prec_sad_gamma = precision_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_prec_happy_gamma = precision_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_prec_sad_gamma = precision_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_prec_happy_gamma = precision_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_prec_sad_gamma = precision_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "rf_rec_happy_gamma = recall_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_rec_sad_gamma = recall_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_rec_happy_gamma = recall_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_rec_sad_gamma = recall_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_rec_happy_gamma = recall_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_rec_sad_gamma = recall_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_rec_happy_gamma = recall_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_rec_sad_gamma = recall_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_rec_happy_gamma = recall_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_rec_sad_gamma = recall_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_rec_happy_gamma = recall_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_rec_sad_gamma = recall_score(yTest, knn_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "rf_f1_happy_gamma = f1_score(yTest, predict, pos_label=\"sadness\")\r\n",
    "rf_f1_sad_gamma = f1_score(yTest, predict, pos_label=\"pleasure\")\r\n",
    "rf_f1_happy_gamma = f1_score(yTest, predict, pos_label=\"anger\")\r\n",
    "rf_f1_sad_gamma = f1_score(yTest, predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "svm_f1_happy_gamma = f1_score(yTest, svm_predict, pos_label=\"sadness\")\r\n",
    "svm_f1_sad_gamma = f1_score(yTest, svm_predict, pos_label=\"pleasure\")\r\n",
    "svm_f1_happy_gamma = f1_score(yTest, svm_predict, pos_label=\"anger\")\r\n",
    "svm_f1_sad_gamma = f1_score(yTest, svm_predict, pos_label=\"joy\")\r\n",
    "\r\n",
    "knn_f1_happy_gamma = f1_score(yTest, knn_predict, pos_label=\"sadness\")\r\n",
    "knn_f1_sad_gamma = f1_score(yTest, knn_predict, pos_label=\"pleasure\")\r\n",
    "knn_f1_happy_gamma = f1_score(yTest, knn_predict, pos_label=\"anger\")\r\n",
    "knn_f1_sad_gamma = f1_score(yTest, knn_predict, pos_label=\"joy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "col_names = ['Subject',\r\n",
    "             'Experiment ID',\r\n",
    "             'Feature extraction',\r\n",
    "             'Band selection',\r\n",
    "             'Channel selection',\r\n",
    "             'Classification algorithm',\r\n",
    "             'Accuracy',\r\n",
    "             'Happy precision',\r\n",
    "             'Sad precision',\r\n",
    "             'Happy recall',\r\n",
    "             'Sad recall',\r\n",
    "             'Happy f1-score',\r\n",
    "             'Sad f1-score']\r\n",
    "\r\n",
    "data_CSV = [subject_id, 5, \"STFT\", \"Delta\", \"-\", \"Random Forest\", rf_acc_delta, rf_prec_happy_delta, rf_prec_sad_delta, rf_rec_happy_delta, rf_rec_sad_delta, rf_f1_happy_delta, rf_f1_sad_delta], [subject_id, 5, \"STFT\", \"Delta\", \"-\", \"SVM\", svm_acc_delta, svm_prec_happy_delta, svm_prec_sad_delta, svm_rec_happy_delta, svm_rec_sad_delta, svm_f1_happy_delta, svm_f1_sad_delta], [subject_id, 5, \"STFT\", \"Delta\", \"-\", \"kNN\", knn_acc_delta, knn_prec_happy_delta, knn_prec_sad_delta, knn_rec_happy_delta, knn_rec_sad_delta, knn_f1_happy_delta, knn_f1_sad_delta], [subject_id, 5, \"STFT\", \"Theta\", \"-\", \"Random Forest\", rf_acc_theta, rf_prec_happy_theta, rf_prec_sad_theta, rf_rec_happy_theta, rf_rec_sad_theta, rf_f1_happy_theta, rf_f1_sad_theta], [subject_id, 5, \"STFT\", \"Theta\", \"-\", \"SVM\", svm_acc_theta, svm_prec_happy_theta, svm_prec_sad_theta, svm_rec_happy_theta, svm_rec_sad_theta, svm_f1_happy_theta, svm_f1_sad_theta], [subject_id, 5, \"STFT\", \"Theta\", \"-\", \"kNN\", knn_acc_theta, knn_prec_happy_theta, knn_prec_sad_theta, knn_rec_happy_theta, knn_rec_sad_theta, knn_f1_happy_theta, knn_f1_sad_theta], [subject_id, 5, \"STFT\", \"Alpha\", \"-\", \"Random Forest\", rf_acc_alpha, rf_prec_happy_alpha, rf_prec_sad_alpha, rf_rec_happy_alpha, rf_rec_sad_alpha, rf_f1_happy_alpha, rf_f1_sad_alpha], [subject_id, 5, \"STFT\", \"Alpha\", \"-\", \"SVM\", svm_acc_alpha, svm_prec_happy_alpha, svm_prec_sad_alpha, svm_rec_happy_alpha, svm_rec_sad_alpha, svm_f1_happy_alpha, svm_f1_sad_alpha], [subject_id, 5, \"STFT\", \"Alpha\", \"-\", \"kNN\", knn_acc_alpha, knn_prec_happy_alpha, knn_prec_sad_alpha, knn_rec_happy_alpha, knn_rec_sad_alpha, knn_f1_happy_alpha, knn_f1_sad_alpha], [subject_id, 5, \"STFT\", \"Beta\", \"-\", \"Random Forest\", rf_acc_beta, rf_prec_happy_beta, rf_prec_sad_beta, rf_rec_happy_beta, rf_rec_sad_beta, rf_f1_happy_beta, rf_f1_sad_beta], [subject_id, 5, \"STFT\", \"Beta\", \"-\", \"SVM\", svm_acc_beta, svm_prec_happy_beta, svm_prec_sad_beta, svm_rec_happy_beta, svm_rec_sad_beta, svm_f1_happy_beta, svm_f1_sad_beta], [subject_id, 5, \"STFT\", \"Beta\", \"-\", \"kNN\", knn_acc_beta, knn_prec_happy_beta, knn_prec_sad_beta, knn_rec_happy_beta, knn_rec_sad_beta, knn_f1_happy_beta, knn_f1_sad_beta], [subject_id, 5, \"STFT\", \"Gamma\", \"-\", \"Random Forest\", rf_acc_gamma, rf_prec_happy_gamma, rf_prec_sad_gamma, rf_rec_happy_gamma, rf_rec_sad_gamma, rf_f1_happy_gamma, rf_f1_sad_gamma], [subject_id, 5, \"STFT\", \"Gamma\", \"-\", \"SVM\", svm_acc_gamma, svm_prec_happy_gamma, svm_prec_sad_gamma, svm_rec_happy_gamma, svm_rec_sad_gamma, svm_f1_happy_gamma, svm_f1_sad_gamma], [subject_id, 5, \"STFT\", \"Gamma\", \"-\", \"kNN\", knn_acc_gamma, knn_prec_happy_gamma, knn_prec_sad_gamma, knn_rec_happy_gamma, knn_rec_sad_gamma, knn_f1_happy_gamma, knn_f1_sad_gamma]\r\n",
    "all_data = data_CSV\r\n",
    "\r\n",
    "csv_df = pd.DataFrame(all_data, columns=col_names)\r\n",
    "\r\n",
    "csv_df.to_csv(\"experiment5.csv\", mode=\"a\", header=col_names, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}