{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "files = os.listdir('data_preprocessed_python\\\\')\n",
    "\n",
    "list_of_dfs = []\n",
    "for file in files:\n",
    "    with open(os.path.join('data_preprocessed_python\\\\',file), 'rb') as pickle_file:\n",
    "        dictRaw = pd.read_pickle(pickle_file) \n",
    "        labels = dictRaw.get('labels')\n",
    "        data = dictRaw.get('data')\n",
    "        \n",
    "        dfLabels = pd.DataFrame(data=labels, columns=[\"valence\", \"arousal\", \"dominance\", \"liking\"])\n",
    "\n",
    "        a,b,c = data.shape\n",
    "        E = data.reshape(40, 322560)\n",
    "        allData = pd.DataFrame(E).transpose()\n",
    "        rows = list()\n",
    "        for _,row in dfLabels.iterrows():\n",
    "            rows += [row]*8064\n",
    "        aux = pd.DataFrame(rows).reset_index(drop=True)\n",
    "        allData = allData.merge(aux, left_index=True, right_index=True)\n",
    "        \n",
    "        list_of_dfs.append(allData)\n",
    "big_df = pd.concat(list_of_dfs, ignore_index=True)#ignore_index to reset index of big_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'big_df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2989c5d20d56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbig_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'arousal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dominance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'liking'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valence'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valence'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'happy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sad'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'FP1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AF3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'T7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Pz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PO3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Oz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PO4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CP2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'T8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FC2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AF4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Fp2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Fz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Cz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'hEOG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'vEOG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'zEMG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tEMG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'GSR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Respiration'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PLethy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Temperature'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'valence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'big_df' is not defined"
     ]
    }
   ],
   "source": [
    "data = big_df.drop(['arousal', 'dominance', 'liking'], axis=1)\n",
    "data['valence'] = np.where(data['valence'] <5, 'happy', 'sad')\n",
    "\n",
    "data.columns = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz','hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature','valence']\n",
    "\n",
    "data.drop(['hEOG','vEOG','zEMG','tEMG','GSR','Respiration','PLethy','Temperature'],axis = 'columns', inplace=True)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "copia = data.copy()\n",
    "\n",
    "y = copia[['valence']]\n",
    "\n",
    "x = copia.drop(columns=['valence'])\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0, verbose=1, n_jobs=5)\n",
    "clf.fit(xTrain, yTrain)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-12-353746cc4ea1>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(xTrain, yTrain)\n",
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_jobs=5, random_state=0, verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend ThreadingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=5)]: Done 100 out of 100 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.650055900452629"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "predict = clf.predict(xTest)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(yTest, predict)"
   ]
  }
 ]
}